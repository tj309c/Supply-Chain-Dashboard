# POP Supply Chain Platform - Project Plan

## üö® CRITICAL DATA INTEGRITY POLICY

**NO FAKE DATA ALLOWED - ZERO TOLERANCE**

This platform must NEVER contain estimated, assumed, or fabricated data. All calculations must use real historical data from source files (ORDERS.csv, DELIVERIES.csv, INVENTORY.csv, etc.).

**Policy Rules:**
1. ‚úÖ **ALLOWED**: Calculations using real data (e.g., `delivered_qty / 90` for daily demand from 90-day historical deliveries)
2. ‚ùå **FORBIDDEN**: Estimates, assumptions, placeholders, or multipliers without real basis (e.g., `backorder_qty * 10` to estimate demand)
3. ‚ùå **FORBIDDEN**: Default values when real data is missing (e.g., adding 30 days to PO create date if expected_delivery_date is missing)
4. ‚úÖ **REQUIRED**: If real data is unavailable, functionality must fail gracefully with clear error messages - NOT use fake data

**Enforcement:**
- Code reviews must verify NO fake data generation
- Any fake data found will be immediately removed
- Comments must clearly mark when real data is unavailable

---

## Executive Summary

This project plan outlines the development roadmap for creating a comprehensive, modular supply chain platform for EssilorLuxottica POP operations. The platform leverages existing data sources to build detailed supply chain modules that integrate seamlessly to provide end-to-end visibility.

**Current Status**: Phase 2 substantially complete - 5 of 8 core modules fully implemented
**Completed Modules**:
- ‚úÖ Inventory Management (with advanced analytics and scrap analysis)
- ‚úÖ SKU Mapping & Alternate Codes (with fulfillment opportunities)
- ‚úÖ Data Upload & Management (with validation and templates)
- ‚úÖ Service Level Tracking (foundation)
- ‚úÖ Backorder Management (foundation with alternate code integration)

**In Progress**: Executive Overview enhancement, Demand Forecasting, Inbound Logistics
**Target**: Modular, scalable platform with integrated supply chain modules

---

## üéØ PRIORITY ROADMAP: Impact vs Ease Matrix

**How to Use This Section**: Start here to identify your next highest-value task. All modules and features are sorted by **Business Impact** (value delivered) and **Implementation Ease** (time/complexity).

### Priority Quadrants

```
High Impact, Easy Implementation (DO FIRST - Quick Wins)
‚îú‚îÄ These deliver maximum value with minimal effort
‚îî‚îÄ Target: Complete within 1-2 weeks each

High Impact, Hard Implementation (DO SECOND - Strategic Investments)
‚îú‚îÄ High value but require more time/complexity
‚îî‚îÄ Target: Plan carefully, allocate 2-4 weeks each

Low Impact, Easy Implementation (DO THIRD - Fill Gaps)
‚îú‚îÄ Nice-to-haves that are quick to implement
‚îî‚îÄ Target: Fit into spare time, 1-2 days each

Low Impact, Hard Implementation (DEFER - Avoid)
‚îú‚îÄ Low ROI, high effort - only do if specifically requested
‚îî‚îÄ Target: Deprioritize or eliminate
```

---

## üöÄ QUADRANT 1: High Impact + Easy (DO FIRST)

**Estimated Total Time**: 6-8 weeks
**Business Value**: Immediate operational improvements

### 1.1 Vendor Scorecard & OTIF Tracking (Week 1-2) ‚≠ê TOP PRIORITY
**Impact**: HIGH - Identifies unreliable vendors causing backorders
**Ease**: EASY - Data already loaded, simple calculations
**Module**: Vendor & Procurement Dashboard (2.6.1)

**Why First**:
- Vendor performance directly impacts backorders and service levels
- Simple metric: On-Time-In-Full delivery %
- Immediate actionable insights (escalate poor performers)

**Quick Win Tasks**:
- [ ] Calculate vendor OTIF % (30/60/90 days)
- [ ] Create vendor ranking table (sortable)
- [ ] Add simple bar chart (vendor comparison)
- [ ] Flag vendors <80% OTIF as "at-risk"
- [ ] Export to Excel

**Deliverable**: One-page vendor scorecard showing top/bottom performers

---

### 1.2 Open PO Dashboard with At-Risk Alerts (Week 2-3) ‚≠ê
**Impact**: HIGH - Prevents backorders by flagging late POs
**Ease**: EASY - Vendor PO data already loaded
**Module**: Vendor & Procurement Dashboard (2.6.2)

**Why This**:
- Proactive visibility into incoming inventory
- Prevents stockouts by escalating late deliveries
- Simple filtering (vendor, SKU, date)

**Quick Win Tasks**:
- [ ] Display open POs table (vendor, SKU, qty, expected delivery)
- [ ] Calculate "days until delivery"
- [ ] Flag POs <7 days out + not shipped as "HIGH RISK"
- [ ] Add filters (vendor, status, urgency)
- [ ] Export open POs to Excel

**Deliverable**: Real-time open PO dashboard with risk flags

---

### 1.3 Backorder-to-PO Linkage (Relief Timeline) (Week 3-4) ‚≠ê
**Impact**: HIGH - Answers "when will backorder be filled?"
**Ease**: MEDIUM-EASY - Matching logic already implemented
**Module**: Backorder Intelligence (2.7.1) - ‚úÖ ALREADY COMPLETED

**Status**: ‚úÖ This is already done! Just needs user adoption.

**Completed Features**:
- ‚úì PO matching by SKU
- ‚úì Vendor-adjusted delivery dates
- ‚úì Relief timeline visualization
- ‚úì Days until relief calculation

**Action**: Focus on user training and adoption of existing feature

---

### 1.4 Pricing Analysis (Vendor Comparison) ‚úÖ COMPLETED
**Impact**: HIGH - Identifies cost savings opportunities
**Ease**: EASY - Price data in vendor PO files
**Module**: Vendor & Procurement Dashboard (2.6.3)

**Status**: ‚úÖ **FULLY IMPLEMENTED** (November 2025)

**Completed Features**:
- ‚úÖ Vendor √ó SKU pricing matrix with historical trends
- ‚úÖ Volume discount effectiveness scoring
- ‚úÖ Price spike detection (configurable thresholds)
- ‚úÖ Multi-vendor price comparison for same SKUs
- ‚úÖ Vendor discount consistency scorecard (0-100 scale)
- ‚úÖ Cost savings opportunities calculator
- ‚úÖ Price elasticity analysis (scatter plots)
- ‚úÖ Pricing anomaly detection (spikes, overpriced, volatile)
- ‚úÖ Excel export functionality
- ‚úÖ Interactive UI with 9 comprehensive sections

**Location**: [pricing_analysis.py](pricing_analysis.py), [vendor_page.py:454-918](pages/vendor_page.py)

**Deliverable**: Fully functional pricing intelligence dashboard with vendor scoring

---

### 1.5 Executive KPI Enhancements (Week 5-6)
**Impact**: HIGH - Executive visibility drives adoption
**Ease**: EASY - Aggregate existing module data
**Module**: Executive Overview (2.10)

**Why This**:
- C-suite visibility = platform adoption
- Simple aggregations of existing metrics
- Minimal new code required

**Quick Win Tasks**:
- [ ] Add vendor performance KPI (avg OTIF %)
- [ ] Add "At-Risk POs" count to overview
- [ ] Add "Cost Savings Opportunities" total
- [ ] Add budget variance summary (once budget module exists)
- [ ] Create executive summary email template

**Deliverable**: Enhanced overview page with cross-module KPIs

---

### 1.6 Demand Forecasting - Statistical Baseline ‚úÖ COMPLETED
**Impact**: HIGH - Enables proactive inventory planning
**Ease**: MEDIUM - Use simple methods (moving average, exponential smoothing)
**Module**: Demand Forecasting (2.8)

**Status**: ‚úÖ **FULLY IMPLEMENTED** (November 2025)

**Completed Features**:
- ‚úÖ 30/60/90 day moving average forecasts per SKU
- ‚úÖ Simple exponential smoothing (alpha=0.3)
- ‚úÖ Forecast accuracy metrics (MAPE, MAE, RMSE) with backtesting
- ‚úÖ 90-day forecast horizon with confidence intervals
- ‚úÖ Demand pattern classification (volatility + trend)
- ‚úÖ Forecast confidence scoring (High/Medium/Low/Very Low)
- ‚úÖ Interactive 4-tab UI with search, filters, and visualizations
- ‚úÖ Excel export functionality
- ‚úÖ Forecast vs actual comparison charts
- ‚úÖ Demand volatility analysis (CV-based classification)
- ‚úÖ Trend detection (growth/decline/flat)

**Test Results**:
- Successfully generates forecasts for all SKUs with 30+ days of history
- Achieved 15.2% average MAPE in testing (excellent accuracy)
- Proper handling of stable, volatile, and trending demand patterns
- 23 comprehensive forecast metrics per SKU

**Location**: [demand_forecasting.py](demand_forecasting.py), [demand_page.py:1-500](pages/demand_page.py)

---

## üíé QUADRANT 2: High Impact + Hard (DO SECOND)

**Estimated Total Time**: 10-14 weeks
**Business Value**: Strategic, transformational features

### 2.1 Budget Tracking & Variance Analysis (Weeks 9-12)
**Impact**: HIGH - Financial accountability and planning
**Ease**: HARD - Requires budget data input, complex variance logic
**Module**: Budget Forecast & Tracking (2.9)

**Why Later**:
- Requires budget data from finance team (external dependency)
- Complex variance decomposition (volume vs price vs mix)
- Needs Phase 2.5 optimization first (heavy calculations)

**Phased Approach**:
- **Phase 1** (Week 9-10): Budget upload + outbound variance only
- **Phase 2** (Week 11): Add inbound variance (with PO commitments)
- **Phase 3** (Week 12): Add inventory variance

**Deliverables**:
- Budget upload template
- Outbound/inbound/inventory variance reports
- Excel export with 6 sheets

---

### 2.2 Demand Forecasting - Hybrid Mode (Weeks 13-16)
**Impact**: HIGH - Better accuracy for promotions and new products
**Ease**: HARD - Requires deterministic inputs + statistical overlay
**Module**: Demand Forecasting (2.8 - TBD Enhancement)

**Why Later**:
- Needs promotional calendar data (may not exist yet)
- Complex integration of business rules + statistics
- Build on top of statistical baseline (1.6)

**Phased Approach**:
- Implement deterministic layer (promotions, lifecycle, commitments)
- Add statistical overlay (error correction, smoothing)
- User toggle between modes

**Deliverables**: Dual-mode forecasting with confidence intervals

---

### 2.3 At-Risk Stockout Prediction (Weeks 17-19)
**Impact**: HIGH - Prevents backorders before they occur
**Ease**: HARD - Safety stock calculations, reorder points
**Module**: Backorder Intelligence (2.7.2)

**Why Later**:
- Requires demand forecast (depends on 1.6)
- Needs vendor lead time data
- Safety stock math is complex

**Phased Approach**:
- Calculate daily demand + variability
- Compute safety stock + reorder points
- Predict "days until stockout"
- Alert on critical items (<7 days)

**Deliverables**: At-risk stockout dashboard with proactive alerts

---

### 2.4 Performance Optimization & Refactoring (Weeks 20-26)
**Impact**: HIGH - Ensures scalability and user experience
**Ease**: MEDIUM-HARD - Requires profiling, caching, refactoring
**Module**: Phase 2.5

**Why This Timing**:
- Execute after 5+ modules complete
- Before Phase 3 integrations
- Prevents technical debt compounding

**See Phase 2.5 section for full 7-week plan**

---

## üéÅ QUADRANT 3: Low Impact + Easy (DO THIRD - Fill Gaps)

**Estimated Total Time**: 2-4 weeks
**Business Value**: Nice-to-haves, polish

### 3.1 Service Level Drill-Down (2-3 days)
**Impact**: MEDIUM - Better root cause analysis
**Ease**: EASY - Data exists, simple filtering
**Module**: Service Level (2.1)

**Quick Adds**:
- Drill-down from customer ‚Üí order ‚Üí line item
- Late delivery root cause categories
- Customer-level trend charts

---

### 3.2 Backorder Root Cause Categorization (2-3 days)
**Impact**: MEDIUM - Identifies systemic issues
**Ease**: EASY - Rule-based categorization
**Module**: Backorder Intelligence (2.7.4)

**Quick Adds**:
- Categorize backorders (no PO, vendor delay, demand spike, etc.)
- Root cause pie chart
- Recommended actions per category

---

### 3.3 Inventory Reorder Point Calculator (3-5 days)
**Impact**: MEDIUM - Guides procurement decisions
**Ease**: MEDIUM-EASY - Simple formula (lead time √ó demand + safety stock)
**Module**: Inventory Management (2.3 - Future Enhancement)

**Quick Adds**:
- Basic reorder point formula
- Flag items below reorder point
- EOQ (Economic Order Quantity) calculation

---

### 3.4 Vendor Concentration Risk Analysis (2-3 days)
**Impact**: MEDIUM - Identifies single-source dependencies
**Ease**: EASY - Simple aggregation
**Module**: Vendor & Procurement (2.6.4)

**Quick Adds**:
- % of total spend by vendor
- Single-source vs multi-source SKUs
- Backup vendor recommendations

---

## üö´ QUADRANT 4: Low Impact + Hard (DEFER)

**Business Value**: Minimal ROI, avoid unless specifically requested

### 4.1 Mobile App Development
**Impact**: LOW - Desktop usage is primary
**Ease**: HARD - Separate codebase, testing
**Recommendation**: DEFER until Phase 4, only if users request

---

### 4.2 Machine Learning Demand Forecasting
**Impact**: LOW-MEDIUM - Statistical methods sufficient initially
**Ease**: HARD - Model training, feature engineering, MLOps
**Recommendation**: DEFER until statistical baseline proven (after 1.6)

---

### 4.3 Workflow Automation Engine
**Impact**: MEDIUM - Manual processes work fine initially
**Ease**: HARD - Complex rules engine, testing
**Recommendation**: DEFER to Phase 3, focus on reports first

---

### 4.4 Multi-Language Support
**Impact**: LOW - English is primary language
**Ease**: HARD - Translation, testing, maintenance
**Recommendation**: DEFER indefinitely unless international expansion

---

## üìã RECOMMENDED EXECUTION SEQUENCE

**Next 8 Weeks (Immediate Focus)**:
1. ‚úÖ Week 1-2: Vendor Scorecard & OTIF
2. ‚úÖ Week 2-3: Open PO Dashboard
3. ‚úÖ Week 3-4: User training on existing backorder relief feature
4. ‚úÖ Week 4-5: Pricing Analysis
5. ‚úÖ Week 5-6: Executive KPI Enhancements
6. ‚úÖ Week 6-8: Demand Forecasting (Statistical Baseline)

**Weeks 9-19 (Strategic Features)**:
7. Week 9-12: Budget Tracking
8. Week 13-16: Demand Forecasting (Hybrid Mode)
9. Week 17-19: At-Risk Stockout Prediction

**Weeks 20-26 (Optimization)**:
10. Week 20-26: Phase 2.5 Performance Optimization

**Weeks 27+ (Polish & Integration)**:
11. Fill gaps from Quadrant 3 as needed
12. Phase 3: Module Integration & Workflows
13. Phase 4: Advanced Features (if needed)

---

## üéØ SUCCESS METRICS BY PRIORITY

**Quadrant 1 (Weeks 1-8) - Target Outcomes**:
- ‚úì Vendor OTIF scores available for all vendors
- ‚úì At-risk POs flagged daily (automated)
- ‚úì Cost savings opportunities identified ($X potential savings)
- ‚úì Executive dashboard viewed weekly by leadership
- ‚úì 90-day demand forecast available for top SKUs
- **User Adoption Goal**: 80% of supply chain team using platform weekly

**Quadrant 2 (Weeks 9-19) - Target Outcomes**:
- ‚úì Budget variance tracked monthly (all categories)
- ‚úì Forecast accuracy >85% (MAPE <15%)
- ‚úì Stockout predictions prevent 50% of backorders
- **User Adoption Goal**: Platform becomes primary tool for planning

**Phase 2.5 (Weeks 20-26) - Target Outcomes**:
- ‚úì Dashboard load time <5 seconds
- ‚úì Memory usage reduced 40%
- ‚úì All performance SLAs met
- **User Satisfaction Goal**: >4/5 rating for responsiveness

---

## Phase 1: Foundation & Current State (COMPLETED ‚úì)

### Achievements
- ‚úÖ Data loading infrastructure (`data_loader.py`, `file_loader.py`)
- ‚úÖ Basic dashboard UI with Streamlit
- ‚úÖ Service Level, Backorder, and Inventory data pipelines
- ‚úÖ Diagnostic and debugging tools
- ‚úÖ Test infrastructure

### Current Data Sources

**‚ö†Ô∏è IMPORTANT NOTE: Domestic Suppliers Only (Current Scope)**

All current inbound and vendor data sources represent **DOMESTIC SUPPLIERS ONLY** (US-based). The platform is currently designed and optimized for domestic supply chain operations.

**Future Scope: International Suppliers** (Phase 3+)
- **Italy suppliers**: Different lead times, customs requirements, currency (EUR)
- **China suppliers**: Extended lead times, import logistics, duty considerations
- **Business Logic Differences**: International suppliers will require separate data views, different KPIs, and specialized logic for:
  - Lead time calculations (ocean freight vs domestic truck)
  - Currency conversion (EUR, CNY)
  - Customs clearance time buffers
  - Incoterms (FOB, CIF, DDP)
  - Port-to-warehouse transit time
  - Import duty and landed cost tracking

**Current Data Sources (Domestic Only)**:
1. **ORDERS.csv** - Customer orders and backorder tracking
2. **DELIVERIES.csv** - Shipment and delivery records
3. **INVENTORY.csv** - Real-time stock levels
4. **Master Data.csv** - Product catalog with SKU metadata
5. **DOMESTIC INBOUND.csv** - Inbound logistics *(domestic suppliers only)*
6. **Domestic Vendor POs.csv** - Purchase order tracking *(domestic suppliers only)*

**Future Data Sources (TBD - International Suppliers)**:
7. **ITALY INBOUND.csv** - Italian supplier inbound shipments (ocean/air freight)
8. **CHINA INBOUND.csv** - China supplier inbound shipments (ocean freight)
9. **International Vendor POs.csv** - International purchase orders with Incoterms
10. **Customs Clearance.csv** - Import documentation and clearance status (optional)

---

## Phase 2: Module Development (IN PROGRESS)

### Goal
Create standalone, interconnected modules that each serve a specific supply chain function while sharing data and integrating seamlessly.

### 2.1 Service Level Module (Priority: HIGH)
**Status**: Foundation exists, needs enhancement

**Objectives**:
- Track on-time delivery performance by customer, SKU, and time period
- Monitor order cycle times
- Identify delivery performance trends
- Alert on service level degradation

**Data Integration**:
- Primary: DELIVERIES.csv, ORDERS.csv
- Supporting: Master Data.csv
- Links to: Backorder Module (late orders), Inventory Module (stock availability)

**Key Features**:
```
‚úì On-time delivery % calculation
‚úì Customer-level performance tracking
‚úì Monthly trend analysis
‚ñ° Real-time alerts for missed commitments
‚ñ° Root cause analysis for late deliveries
‚ñ° Customer satisfaction scoring
‚ñ° Predictive late delivery warnings
```

**Technical Tasks**:
- [ ] Enhance `pages/service_level_page.py` with advanced analytics
- [ ] Add drill-down capabilities (customer ‚Üí order ‚Üí line item)
- [ ] Implement alerting system for SLA breaches
- [ ] Create export templates for customer reporting
- [ ] Add comparison views (YoY, MoM)

---

### 2.2 Backorder Management Module (Priority: HIGH)
**Status**: Foundation exists, needs enhancement

**Objectives**:
- Visibility into all open backorders
- Aging analysis and prioritization
- Root cause identification
- Customer impact assessment

**Data Integration**:
- Primary: ORDERS.csv
- Supporting: Master Data.csv, INVENTORY.csv
- Links to: Inventory Module (stock availability), Inbound Module (incoming supply)

**Key Features**:
```
‚úì Current backorder quantity tracking
‚úì Aging analysis (0-7, 8-14, 15-30, 30+ days)
‚úì Customer and SKU breakdowns
‚ñ° Fulfillment priority ranking
‚ñ° Expected resolution dates (linked to inbound POs)
‚ñ° Customer communication templates
‚ñ° Backorder root cause categorization
‚ñ° Auto-allocation when stock arrives
```

**Technical Tasks**:
- [ ] Create dedicated backorder page in new UI structure
- [ ] Implement priority scoring algorithm
- [ ] Link backorders to incoming POs for ETA calculation
- [ ] Build "what-if" scenarios (if X stock arrives, which orders fill?)
- [ ] Add workflow for backorder resolution tracking

---

### 2.3 Inventory Management Module (Priority: HIGH)
**Status**: ‚úÖ COMPLETED - Fully Enhanced with Advanced Features

**Objectives**:
- Real-time inventory visibility with currency conversion
- ABC analysis for value-based prioritization
- Days-on-hand and turnover tracking
- Slow-moving and obsolete inventory identification
- Scrap opportunity analysis with adjustable thresholds
- Stock-out risk monitoring and alerts
- Category-level performance benchmarking
- Future-ready for historical trend analysis

**Data Integration**:
- Primary: INVENTORY.csv
- Supporting: DELIVERIES.csv (demand calculation), Master Data.csv (product attributes)
- Links to: Backorder Module (allocation), Service Level Module (fulfillment capability)
- Business Rules: Centralized in `business_rules.py` for maintainability

**Key Features**:
```
‚úì Current stock levels by SKU
‚úì Stock aggregation by SKU with pricing
‚úì Days of inventory outstanding (DIO) calculation
‚úì Inventory value tracking with USD/EUR currency conversion
‚úì Movement classification (Fast/Normal/Slow/Very Slow/Obsolete/Dead Stock)
‚úì ABC Analysis with Pareto visualization (80/15/5 rule)
‚úì Stock-out risk alerts (Critical/Warning/Safe levels)
‚úì Slow-moving inventory identification and analysis
‚úì Scrap opportunity analysis with adjustable threshold (default: 2 years)
‚úì Category benchmarking with DIO heat map
‚úì Interactive filtering (category, movement class, ABC class, stock-out risk, DIO range)
‚úì SKU search capability (partial match)
‚úì DIO distribution visualization (7 age buckets)
‚úì Movement classification pie chart
‚úì ABC analysis Pareto chart
‚úì Top 50 slow-moving items by value with ABC classification
‚úì Detailed scrap candidate reporting with value breakdown
‚úì Critical stock-out risk items highlighted
‚úì Downloadable CSV exports for all analyses (currency-specific)
‚úì Adjustable settings (scrap threshold, stock-out threshold, currency)
‚úì Structure for future monthly inventory snapshots
‚ñ° Reorder point calculator - FUTURE ENHANCEMENT
‚ñ° Inventory optimization recommendations - FUTURE ENHANCEMENT
‚ñ° Multi-location inventory view - FUTURE ENHANCEMENT
‚ñ° Historical trend analysis (requires monthly snapshots) - FUTURE ENHANCEMENT
```

**Technical Tasks**:
- [x] Create comprehensive inventory page (`pages/inventory_page.py`)
- [x] Implement DIO calculation using historical delivery data
- [x] Build inventory movement classification system (via business_rules.py)
- [x] Create slow-moving/obsolescence identification logic
- [x] Develop scrap opportunity analysis section with adjustable threshold
- [x] Add interactive filters (category, movement class, ABC, risk, DIO range)
- [x] Implement SKU search functionality
- [x] Build DIO distribution chart with currency support
- [x] Create movement classification pie chart
- [x] Implement ABC analysis with Pareto chart
- [x] Add stock-out risk analysis section
- [x] Build category benchmarking heat map
- [x] Implement top slow-movers table with ABC classification
- [x] Add detailed scrap candidate list with downloads
- [x] Implement currency conversion (USD/EUR with 0.9 rate)
- [x] Create business_rules.py for centralized rule management
- [x] Add adjustable settings sidebar (currency, thresholds)
- [x] Set up placeholder structure for future monthly snapshots
- [ ] Add reorder point and EOQ calculations - FUTURE
- [ ] Create inventory optimization recommendations - FUTURE
- [ ] Multi-location inventory balancing logic - FUTURE
- [ ] Implement historical trend charts (once snapshot data available) - FUTURE

**Future Inventory Enhancements** (Priority: MEDIUM):
```
Planned enhancements for inventory module:

1. Reorder Point Calculator
   - Calculate safety stock based on lead time and demand variability
   - Flag items below reorder point
   - EOQ (Economic Order Quantity) calculations
   - Min/max inventory level recommendations

2. Inventory Optimization Recommendations
   - "What-if" scenarios: impact analysis of scrap decisions
   - Target stock level suggestions based on service level goals
   - Cost optimization (holding cost vs stock-out cost)
   - Automated replenishment suggestions

3. Multi-Location Inventory View
   - Break down inventory by warehouse/distribution center
   - Inter-location transfer recommendations
   - Location-specific DIO and ABC analysis
   - Stock balancing opportunities

4. Historical Trend Analysis
   - Monthly inventory snapshots tracking
   - DIO trend over time (improving/deteriorating)
   - Inventory value trend charts
   - Seasonal pattern detection
   - Movement classification migration tracking

5. Integration with Backorders
   - Cross-reference slow-movers with demand
   - Identify data quality issues (obsolete items on backorder)
   - Prioritize stock-out vs scrap decisions
```

---

### 2.4 User Data Upload & Management Module (Priority: HIGH)
**Status**: ‚úÖ COMPLETED - Full Implementation with Validation

**Objectives**:
- Enable users to upload their own source data files
- Provide data validation and error checking
- Clear cached data and load fresh user-uploaded data
- Provide template files for each required data source
- Ensure data quality and consistency

**Data Sources Supported**:
1. **ORDERS.csv** - Customer orders and backorder tracking
2. **DELIVERIES.csv** - Shipment and delivery records
3. **INVENTORY.csv** - Real-time stock levels
4. **Master Data.csv** - Product catalog with SKU metadata
5. **DOMESTIC INBOUND.csv** - Inbound logistics (optional)
6. **Domestic Vendor POs.csv** - Purchase order tracking (optional)
7. **ALTERNATE_CODES.csv** - SKU alternate/legacy code mappings (optional)

**Key Features**:
```
‚úì File upload interface for each data source
‚úì Template export functionality (CSV templates with correct column headers and sample data)
‚úì Data validation on upload (column checks, data type validation, business rules)
‚úì Preview uploaded data before processing (first 5 rows)
‚úì Error reporting with specific row/column details
‚úì Clear cache and reload with user data
‚úì File size and format checking (200MB limit, CSV only)
‚úì Success/failure notifications with actionable messages
‚úì Data source status dashboard (which files loaded, when, row counts)
‚úì Upload history and audit trail (last 10 uploads)
‚úì Session state management for uploaded files
‚úì Required vs optional file indicators
```

**Template Export Specifications**:
```
Each template should include:
- All required column headers in correct order
- Data type hints (via sample row or comments)
- Required vs optional field indicators
- Example data rows (1-2 samples)
- Instructions/notes in header comment
- File naming convention guidance
```

**Validation Rules**:
```
1. ORDERS.csv:
   - Required columns: Orders Detail - Order Document Number, Item - SAP Model Code,
     Order Creation Date: Date, Original Customer Name, Orders - TOTAL Orders Qty,
     Orders - TOTAL To Be Delivered Qty, Orders - TOTAL Cancelled Qty
   - Date format: M/D/YY
   - Numeric fields: Orders Qty, To Be Delivered Qty, Cancelled Qty
   - No duplicate order line items (Order Number + SKU)

2. DELIVERIES.csv:
   - Required columns: Deliveries Detail - Order Document Number, Item - SAP Model Code,
     Delivery Creation Date: Date, Deliveries - TOTAL Goods Issue Qty
   - Date format: M/D/YY
   - Numeric fields: Goods Issue Qty
   - Delivery date must be >= order date (if joined)

3. INVENTORY.csv:
   - Required columns: Storage Location, Material Number, Free Qt, Last Purchase Price
   - Numeric fields: Free Qt, Last Purchase Price
   - No negative quantities
   - No duplicate SKU+Location combinations

4. Master Data.csv:
   - Required columns: Material Number, PLM: Level Classification 4, Activation Date (Code),
     PLM: PLM Current Status, PLM: Expiration Date
   - Date format: Activation (M/D/YY), Expiration (YYYYMMDD)
   - No duplicate Material Numbers
   - Activation date must be <= Today

5. ALTERNATE_CODES.csv:
   - Required columns: SAP Material Current, SAP Material Last Old Code,
     SAP Material Original Code
   - All codes must be valid strings
   - Current code cannot be blank
```

**Technical Tasks**:
- [x] Create data upload page (`pages/data_upload_page.py`)
- [x] Build file upload widgets for each data source (required and optional files)
- [x] Implement template export function with correct headers and sample data
- [x] Create validation framework for each file type (ORDERS, DELIVERIES, INVENTORY, Master Data, ALTERNATE_CODES)
- [x] Build error reporting UI with detailed messages (specific validation errors per file)
- [x] Add data preview functionality (first 5 rows of uploaded data)
- [x] Implement cache clearing mechanism (üîÑ Refresh Dashboard button)
- [x] Create data source status dashboard (shows file name, rows, timestamp, status)
- [x] Add clear all uploads action (üóëÔ∏è Clear All Uploads button)
- [x] Build upload history tracking (last 10 upload attempts with status)
- [x] Add file size limits and format checking (200MB limit, CSV only)
- [x] Implement session state management for uploaded files
- [x] Create user documentation for upload process (üìñ Instructions expander)
- [x] Add success/error notifications with actionable guidance

**User Interface Design**:
```
‚îå‚îÄ Data Upload & Management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                 ‚îÇ
‚îÇ üì• Upload Data Sources                          ‚îÇ
‚îÇ ‚îú‚îÄ Required Files (3/3 uploaded)               ‚îÇ
‚îÇ ‚îÇ  ‚úì ORDERS.csv         [Replace] [Template]  ‚îÇ
‚îÇ ‚îÇ  ‚úì DELIVERIES.csv     [Replace] [Template]  ‚îÇ
‚îÇ ‚îÇ  ‚úì INVENTORY.csv      [Replace] [Template]  ‚îÇ
‚îÇ ‚îÇ  ‚úì Master Data.csv    [Replace] [Template]  ‚îÇ
‚îÇ ‚îÇ                                              ‚îÇ
‚îÇ ‚îî‚îÄ Optional Files (1/3 uploaded)               ‚îÇ
‚îÇ    ‚úì ALTERNATE_CODES.csv [Replace] [Template]  ‚îÇ
‚îÇ    ‚óã DOMESTIC INBOUND.csv  [Upload] [Template] ‚îÇ
‚îÇ    ‚óã Domestic Vendor POs   [Upload] [Template] ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üìä Data Status                                  ‚îÇ
‚îÇ ‚îú‚îÄ ORDERS: 45,231 rows | Last updated: 2025-11-21 14:32 ‚îÇ
‚îÇ ‚îú‚îÄ DELIVERIES: 123,456 rows | Last updated: 2025-11-21 14:32 ‚îÇ
‚îÇ ‚îú‚îÄ INVENTORY: 8,942 rows | Last updated: 2025-11-21 14:32 ‚îÇ
‚îÇ ‚îî‚îÄ Master Data: 12,384 rows | Last updated: 2025-11-21 14:32 ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ ‚öôÔ∏è Actions                                       ‚îÇ
‚îÇ [üîÑ Refresh All Data] [üóëÔ∏è Clear Cache]        ‚îÇ
‚îÇ [üì• Download All Templates] [‚Ü©Ô∏è Restore Defaults] ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üìú Upload History (Last 10)                     ‚îÇ
‚îÇ ‚îî‚îÄ Table with: Timestamp, File, User, Status, Rows ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Integration**:
- ‚úì Added to main dashboard navigation as "üì§ Data Management"
- ‚úì Integrated with existing data_loader.py infrastructure
- ‚úì Uses file_loader.py safe_read_csv with session state
- ‚úì Session state management for uploaded files

---

### 2.5 SKU Mapping & Alternate Codes Module (Priority: HIGH)
**Status**: ‚úÖ COMPLETED - Full Implementation with Business Rules

**Objectives**:
- Manage material code transitions and SKU supersessions
- Track inventory split across old and current material codes
- Identify backorder fulfillment opportunities via code updates
- Ensure data consistency across alternate code families
- Support inventory consolidation strategies

**Data Integration**:
- Primary: ALTERNATE_CODES.csv
- Supporting: INVENTORY.csv, ORDERS.csv (backorders)
- Links to: Inventory Module (code consolidation), Backorder Module (fulfillment opportunities)
- Business Rules: ALTERNATE_CODES_RULES in business_rules.py

**Key Features**:
```
‚úì Bidirectional material code mapping (current ‚Üî old codes)
‚úì SKU family tracking (current + all historical codes)
‚úì Inventory split analysis across alternate codes
‚úì Backorder fulfillment opportunity identification
‚úì SKU lookup tool with code family display
‚úì Alternate code alerts on inventory page
‚úì Alternate code opportunities on backorder page
‚úì Business rule: Prioritize old inventory first before new
‚úì Alert on old code backorders when current code has inventory
‚úì Warehouse scrap list includes alternate codes
‚úì Global caching for performance optimization
‚úì Automatic code normalization in reports
```

**Business Rules** (Centralized in business_rules.py):
```
Normalization:
- Auto-normalize old codes to current codes in aggregated views
- Aggregate inventory across alternate codes
- Aggregate historical demand across alternate codes
- Show backorders with current code reference

Display:
- Show alternate codes in tooltips/columns
- Highlight when displaying old code data
- Maximum 3 alternate codes in tooltip display

Alerts:
- Alert when backorders exist on old codes
- Alert when inventory split across codes
- Alert on ANY old code backorder (threshold: 0)

Business Logic:
- Recommend updating orders from old to current code
- Prioritize using old SKU inventory first before new
- Track which code has which inventory
- Consolidate all reports under current code

Data Quality:
- Flag missing current codes
- Flag circular code references
- Validate code hierarchy integrity
```

**Technical Tasks**:
- [x] Create SKU mapping page (`pages/sku_mapping_page.py`)
- [x] Implement alternate codes loading (`load_alternate_codes_mapping()`)
- [x] Build bidirectional code mapping (current_to_old, old_to_current, all_codes_by_family)
- [x] Create inventory split analysis function
- [x] Build backorder fulfillment opportunity finder
- [x] Implement SKU lookup tool with family display
- [x] Add alternate code alerts to inventory page (`render_alternate_code_alerts()`)
- [x] Add alternate code opportunities to backorder page (`render_alternate_code_opportunities()`)
- [x] Integrate alternate codes into warehouse scrap list export
- [x] Implement helper functions (get_current_code, get_alternate_codes, is_old_code, has_alternate_codes)
- [x] Add global caching for alternate codes mapping
- [x] Create ALTERNATE_CODES_RULES in business_rules.py
- [x] Add to main dashboard navigation as "üîÑ SKU Mapping"
- [x] Support multiple encodings for ALTERNATE_CODES.csv (UTF-8, Latin-1, CP1252)

**Integration Points**:
- ‚úì Inventory Page: Shows alerts for split inventory across code families
- ‚úì Backorder Page: Shows fulfillment opportunities for old code backorders
- ‚úì Warehouse Scrap List: Includes alternate codes column
- ‚úì SKU Mapping Page: Dedicated page for code management and analysis
- ‚úì Business Rules: Centralized alternate codes configuration

**User Workflows Enabled**:
1. **Inventory Consolidation**: Identify and consolidate inventory split across old/new codes
2. **Backorder Resolution**: Update old code backorders to current code to fulfill with available stock
3. **SKU Lookup**: Search any SKU and see its full code family (current + all historical codes)
4. **Data Quality**: Identify and fix issues with obsolete code usage

---

### 2.6 Vendor & Procurement Dashboard Module (Priority: HIGH)
**Status**: NEW - Data sources available, ready for development

**‚ö†Ô∏è CURRENT SCOPE: DOMESTIC SUPPLIERS ONLY**

**Current Implementation**: This module currently tracks **DOMESTIC SUPPLIERS ONLY** (US-based vendors with truck/ground shipping). All business logic, lead time calculations, and KPIs are optimized for domestic supply chain operations.

**Future Enhancement: International Suppliers** (Phase 3+ - TBD)

When international suppliers (Italy, China) are added, this module will require **significant enhancements**:

**Italy Suppliers - Specific Requirements**:
- Currency: EUR (with dynamic exchange rates)
- Lead times: 15-30 days (ocean/air freight vs 3-7 days domestic)
- Incoterms tracking (FOB, CIF, DDP)
- Customs clearance buffer (3-5 days)
- Port-to-warehouse transit time
- Separate OTIF calculation (considering customs delays)
- Duty and landed cost integration

**China Suppliers - Specific Requirements**:
- Currency: CNY (with dynamic exchange rates)
- Lead times: 30-60 days (ocean freight)
- Container tracking integration
- Port congestion factors
- Customs broker coordination
- Import duty calculations
- Separate vendor scorecard (different benchmarks)

**Technical Architecture for International Suppliers**:
```python
# Future data structure
class VendorProfile:
    vendor_type: str  # 'domestic', 'italy', 'china'
    base_currency: str
    avg_lead_time_days: int
    customs_buffer_days: int  # 0 for domestic, 3-5 for international
    incoterm: str  # 'FOB', 'CIF', 'DDP', etc.

# Separate business logic by vendor type
VENDOR_RULES = {
    "domestic": {
        "lead_time_target": 7,
        "otif_target": 95,
        "currency": "USD"
    },
    "italy": {
        "lead_time_target": 25,
        "otif_target": 85,  # Lower due to customs complexity
        "currency": "EUR",
        "customs_buffer": 4
    },
    "china": {
        "lead_time_target": 45,
        "otif_target": 80,
        "currency": "CNY",
        "customs_buffer": 5
    }
}
```

**UI Changes for International Suppliers**:
- **Vendor Type Filter**: Domestic / Italy / China / All
- **Separate Scorecards**: Different OTIF targets by vendor type
- **Lead Time Breakdown**: Manufacturing ‚Üí Shipping ‚Üí Customs ‚Üí Delivery
- **Currency Display**: Multi-currency support with conversion
- **Landed Cost View**: Base price + freight + duty + customs fees

**Data Sources for International Suppliers** (Future):
- **ITALY_INBOUND.csv**: Italian supplier shipments with Incoterms
- **CHINA_INBOUND.csv**: China supplier shipments with container tracking
- **CUSTOMS_CLEARANCE.csv**: Import documentation and clearance timeline
- **EXCHANGE_RATES.csv**: Daily EUR/CNY exchange rates (or API integration)

**Implementation Approach**:
1. **Phase 1 (Current)**: Build domestic-only module with extensible architecture
2. **Phase 2 (Future)**: Add vendor_type field to data model
3. **Phase 3 (Future)**: Implement separate business logic per vendor type
4. **Phase 4 (Future)**: Add international-specific UI views and KPIs

---

**Objectives**:
- Comprehensive vendor performance management and scorecarding
- Purchase order lifecycle tracking and visibility
- Lead time analysis and variance monitoring
- Pricing intelligence and cost analysis
- At-risk PO identification and escalation
- Support demand planning and reorder point calculations

**Data Integration (Current - Domestic Only)**:
- Primary: `Domestic Vendor POs.csv`, `DOMESTIC INBOUND.csv` *(domestic suppliers only)*
- Supporting: `INVENTORY.csv` (receipts), `Master Data.csv`, `DELIVERIES.csv` (demand)
- Links to: Backorder Module (expected relief), Inventory Module (incoming stock), Demand Planning (future)

---

#### 2.6.1 Vendor Performance & Scorecarding

**Core Features**:
```
‚ñ° Vendor scorecard with weighted metrics
  - On-Time Delivery % (OTIF - On Time In Full)
  - Lead time consistency (planned vs actual variance)
  - Receipt accuracy (quantity/quality variance)
  - Pricing competitiveness
  - Response time to changes/inquiries

‚ñ° Service level by vendor
  - Rolling 30/60/90 day performance
  - Trend analysis (improving/declining)
  - Category-level breakdowns

‚ñ° Lead time variance analysis
  - Planned vs actual lead time tracking
  - Variance by vendor, by SKU, by category
  - Alert thresholds for excessive variance
  - Historical lead time trends

‚ñ° Vendor comparison & benchmarking
  - Side-by-side vendor performance
  - Best-in-class identification
  - Vendor ranking by category
```

**Open Questions**:
- **Scoring Methodology**: What factors and weights for vendor scoring? (e.g., 40% OTIF, 30% lead time, 20% pricing, 10% quality)
- **Performance Thresholds**: Define "good" vs "poor" vendor performance benchmarks
- **Quality Metrics**: Do we have quality/defect data to include in scoring?

---

#### 2.6.2 Purchase Order Management

**Core Features**:
```
‚ñ° PO lifecycle tracking
  - Status: Created ‚Üí Confirmed ‚Üí Shipped ‚Üí Received ‚Üí Closed
  - PO aging by status (open POs by age bucket)
  - Timeline visualization per PO

‚ñ° Open purchase orders dashboard
  - Filter by vendor, SKU, date range, status
  - Sort by urgency, value, age
  - Export functionality

‚ñ° At-risk PO identification
  - Late POs (approaching delivery date but not shipped)
  - Vendor reliability risk (poor historical performance)
  - Extended lead time alerts
  - Cross-reference with backorders for criticality

‚ñ° Receipt variance analysis
  - Ordered vs received quantity
  - Ordered vs received value
  - Variance by vendor (consistent over/under delivery)
  - Root cause categorization

‚ñ° PO expedite recommendations
  - Automated flagging based on:
    - Days until expected delivery
    - Linked to critical backorders
    - Vendor historical delays
  - Escalation workflow tracking

‚ñ° Abnormal purchase detection (SMART ALERTS)
  - Over-purchasing vs demand/usage alerts:
    - PO quantity >> recent demand/usage pattern
    - SKU with no recent usage (dead stock risk)
    - Order quantity exceeds X months of supply
  - Pricing anomaly detection:
    - Unit price significantly above historical average
    - Price spike vs. recent PO pricing for same SKU
    - Vendor pricing above competitor pricing
  - Inventory duplication risk:
    - Purchasing SKU with high existing on-hand inventory
    - PO for SKU already on order (duplicate PO risk)
  - Business rule violations:
    - Ordering discontinued/expired SKUs
    - Purchasing from non-preferred/low-scoring vendors
```

**Open Questions**:
- **At-Risk Criteria**: Define specific thresholds (e.g., <7 days to delivery + not shipped = high risk)
- **PO Status Tracking**: Do current data files include PO status, or do we infer from dates?

---

#### 2.6.3 Pricing Intelligence & Cost Analysis

**Core Features**:
```
‚ñ° Pricing matrix analysis
  - Vendor √ó SKU pricing grid
  - Vendor √ó Time period trends
  - Vendor √ó Order quantity (volume discounts)

‚ñ° Price variance tracking
  - Price changes over time by vendor/SKU
  - Alert on significant price increases (>X%)
  - Historical pricing trends

‚ñ° Vendor comparison pricing
  - Same SKU across multiple vendors
  - Identify lowest cost supplier by SKU
  - Total cost of ownership (price + lead time + reliability)

‚ñ° Cost savings opportunities
  - Alternative vendor recommendations
  - Volume consolidation opportunities
  - Price negotiation targets
```

**Open Questions**:
- **Pricing Dimensions**: Which analysis dimensions are most valuable? (vendor√óSKU, vendor√ótime, vendor√óvolume)
- **Historical Pricing**: How far back should pricing history go?
- **TCO Calculation**: Should we include holding costs, expedite fees, etc. in total cost?

---

#### 2.6.4 Strategic Procurement Insights

**Core Features**:
```
‚ñ° Vendor concentration analysis
  - % of total spend by vendor
  - Dependency risk identification
  - Diversification recommendations

‚ñ° SKU sourcing analysis
  - Single-source vs multi-source items
  - Identify sole-source risks
  - Backup vendor recommendations

‚ñ° Capacity & volume analysis
  - Vendor capacity tracking (if data available)
  - Volume trends by vendor
  - Forecast vs actual order volume

‚ñ° Preferred vendor recommendations
  - Best vendor by SKU/category based on composite score
  - Alternative vendor suggestions
  - New vendor evaluation framework
```

**Open Questions**:
- **Vendor Capacity Data**: Do we have vendor capacity information, or should we infer from order patterns?
- **Spend Data**: Is total spend per vendor available, or should we calculate from PO history?

---

#### 2.6.5 Integration with Demand Planning & Inventory

**Future-Ready Features** (Phase 3):
```
‚ñ° Reorder point calculation inputs
  - Expected receipt dates from open POs
  - Vendor lead time data (avg, min, max)
  - Lead time variability (for safety stock calc)

‚ñ° Demand planning integration
  - Vendor reliability metrics ‚Üí safety stock adjustments
  - Lead time data ‚Üí reorder point timing
  - Historical delivery patterns ‚Üí forecast accuracy

‚ñ° Backorder relief tracking
  - Link open POs to specific backorders (by SKU)
  - Calculate "days until backorder filled" (PO expected delivery - today)
  - Display expected relief date on backorder page
  - Prioritize backorders with incoming PO relief
  - Automatic allocation on receipt (future)

‚ñ° Inventory replenishment
  - Suggested PO creation based on reorder points
  - Vendor selection recommendations
  - Order quantity optimization
```

**Open Questions**:
- **Reorder Point Fields**: Which specific data points are needed for ROP calculations?
- **Safety Stock Factors**: How should vendor reliability affect safety stock levels?
- **Auto-Allocation Logic**: Should stock auto-allocate to backorders on receipt, or require manual confirmation?

---

#### 2.6.6 Operational Tools

**Core Features**:
```
‚ñ° Delivery schedule compliance
  - Planned vs actual delivery dates
  - Schedule adherence % by vendor
  - Delay pattern analysis

‚ñ° Payment terms analysis
  - Terms by vendor (Net 30, Net 60, etc.)
  - Cash flow impact visibility
  - Early payment discount opportunities

‚ñ° Collaborative planning tools
  - Shared forecast visibility (future)
  - Vendor portal integration (future)
  - Communication history tracking
```

---

### Implementation Roadmap

**Phase 1: Quick Wins (Weeks 1-2)** - START HERE
```
Priority: Easiest + Most Impactful

1. PO Data Loader (HIGH IMPACT, MEDIUM EFFORT)
   - Load Domestic Vendor POs.csv and DOMESTIC INBOUND.csv
   - Basic data cleaning and validation
   - Create unified PO dataset

2. Open PO Dashboard (HIGH IMPACT, LOW EFFORT)
   - Simple table view of open POs
   - Filter by vendor, status, age
   - Export to Excel
   - Days-to-delivery calculation

3. Vendor Service Level (HIGH IMPACT, LOW EFFORT)
   - On-time delivery % by vendor
   - Simple bar chart ranking
   - 30/60/90 day rolling metrics

4. At-Risk PO Alerts (HIGH IMPACT, LOW EFFORT)
   - Flag POs approaching delivery date
   - Highlight vendor with poor performance
   - Link to backorders for criticality
```

**Phase 2: Analytics & Insights (Weeks 3-4)**
```
1. Lead Time Variance Analysis
   - Planned vs actual lead time tracking
   - Variance charts by vendor
   - Alert configuration

2. Vendor Scorecarding
   - Weighted composite score
   - Multi-factor performance evaluation
   - Trend tracking

3. Pricing Intelligence
   - Pricing matrix (vendor √ó SKU)
   - Historical price trends
   - Vendor comparison tool
```

**Phase 3: Advanced Features (Weeks 5-6)**
```
1. Receipt Variance Analysis
2. Strategic Sourcing Insights
3. Demand Planning Integration
4. Predictive Analytics
```

---

### Technical Implementation

**Data Loader Structure**:
```python
# data_loader.py additions
def load_vendor_pos(po_path, file_key='vendor_pos'):
    """Load vendor purchase order data"""
    # Columns: PO Number, Vendor, SKU, Order Date, Expected Delivery,
    #          Order Qty, Unit Price, PO Status, etc.

def load_inbound_data(inbound_path, file_key='inbound'):
    """Load inbound shipment/receipt data"""
    # Columns: PO Number, Receipt Date, Received Qty, Receipt Status, etc.

def load_vendor_performance(po_df, inbound_df, master_df):
    """Calculate vendor performance metrics"""
    # Join POs with receipts, calculate OTIF, lead time variance, etc.
```

**Page Structure**:
```python
# pages/vendor_page.py
def render_vendor_page(vendor_data, po_data, inbound_data):
    """Main vendor dashboard"""
    # Tabs: Overview, Open POs, Vendor Scorecards, Pricing, At-Risk POs
```

**Business Rules**:
```python
# business_rules.py additions
VENDOR_RULES = {
    "scoring_weights": {
        "otif": 0.40,           # On-time in-full delivery
        "lead_time": 0.30,      # Lead time consistency
        "pricing": 0.20,        # Price competitiveness
        "quality": 0.10         # Quality/accuracy
    },
    "performance_thresholds": {
        "excellent": 95,        # >= 95% = Excellent
        "good": 85,            # >= 85% = Good
        "acceptable": 75,      # >= 75% = Acceptable
        "poor": 75             # < 75% = Poor
    },
    "at_risk_criteria": {
        "days_until_delivery": 7,     # < 7 days = urgent
        "vendor_otif_threshold": 80    # < 80% vendor OTIF = risky
    },
    "lead_time_variance": {
        "acceptable_range": 0.15,      # ¬±15% variance acceptable
        "alert_threshold": 0.25        # >25% variance = alert
    }
}
```

---

### Success Metrics

**Module Completion Criteria**:
- [x] Vendor PO data successfully loaded and integrated
- [ ] Open PO dashboard with filtering and export
- [ ] Vendor service level (OTIF) calculation and visualization
- [ ] At-risk PO identification and alerting
- [ ] Lead time variance tracking
- [ ] Vendor scorecard with composite scoring
- [ ] Unit tests for vendor calculations (>80% coverage)
- [ ] User documentation

**Business Impact KPIs**:
- **Vendor Performance**: Track OTIF % improvement over time
- **At-Risk PO Reduction**: Reduce late POs by 20%+
- **Cost Savings**: Identify pricing opportunities worth $X
- **Lead Time Reduction**: Improve average lead time consistency by 15%
- **Backorder Resolution**: Faster backorder relief through better PO visibility

---

### 2.7 Backorder Intelligence & Predictive Analytics (Priority: HIGH)
**Status**: IN PROGRESS - Enhanced backorder analytics with vendor integration

**Objectives**:
- Integrate vendor PO data to calculate expected backorder relief dates
- Predict stockout risk before backorders occur using demand and safety stock
- Enhanced prioritization using vendor reliability and customer impact
- Root cause analysis to identify systemic backorder issues
- Provide actionable intelligence for backorder resolution

**Data Integration**:
- Primary: Backorder data, Vendor POs, Inbound receipts, Vendor performance
- Supporting: Inventory, Deliveries (demand), Master Data
- Links to: Vendor Module (PO relief), Inventory Module (at-risk prediction)

---

#### 2.7.1 PO Relief Date Integration (Week 1 - PRIORITY 1)

**Objectives**:
- Link backorders to expected vendor PO deliveries
- Calculate vendor-adjusted relief dates based on historical performance
- Show "Days Until Relief" for each backorder
- Identify backorders with NO PO coverage (critical gap)

**Core Features**:
```
‚úì PO-to-Backorder Matching
  - Match by SKU to find relieving POs
  - Handle multiple POs per SKU (prioritize nearest delivery)
  - Flag backorders with no matching PO

‚úì Vendor-Adjusted Delivery Dates
  - Expected Relief Date = PO Expected Delivery + Vendor Avg Delay
  - Use vendor OTIF % and average delay days from vendor_performance
  - Confidence scoring: High (>90% OTIF), Medium (75-90%), Low (<75%)

‚úì Relief Timeline Visualization
  - Gantt-style timeline showing when backorders clear
  - Color-coded by confidence (Green/Yellow/Red)
  - Group by: This Week, This Month, Next Month, No PO

‚úì New Metrics
  - "Backorders with PO Coverage" (% with matching PO)
  - "Avg Days Until Relief" (weighted average)
  - "High-Risk Backorders" (unreliable vendor or no PO)
  - "Backorders Relieving in Next 7/30 Days"
```

**Technical Implementation**:
```python
# New module: backorder_relief_analysis.py
def calculate_backorder_relief_dates(backorder_df, vendor_pos_df, vendor_performance_df):
    """
    Match backorders to POs and calculate expected relief

    Returns DataFrame with:
    - All backorder fields
    - relieving_po_number
    - po_expected_delivery
    - vendor_name
    - vendor_otif_pct
    - vendor_avg_delay_days
    - vendor_adjusted_delivery_date
    - days_until_relief
    - relief_confidence ('High'/'Medium'/'Low')
    - has_po_coverage (True/False)
    """
```

**New Tab**: "üìÖ Relief Timeline & PO Tracking"

**Tasks**:
- [x] Create `backorder_relief_analysis.py` module
- [x] Implement PO-to-backorder matching by SKU
- [x] Calculate vendor-adjusted relief dates
- [x] Add relief confidence scoring
- [x] Create "Relief Timeline" tab with Gantt visualization
- [x] Add new KPI metrics to overview tab (PO Coverage, Avg Days to Relief, High-Risk)
- [ ] Update priority scoring to include days_until_relief (optional enhancement)

**Implementation Notes**:
- Created `backorder_relief_analysis.py` with full PO matching logic
- Added `load_backorder_relief()` to data_loader.py
- Integrated relief calculation into dashboard_simple.py (99% progress step)
- Updated backorder_page.py with:
  - 3 new KPI metrics (PO Coverage %, Avg Days to Relief, High-Risk count)
  - New "üìÖ Relief Timeline & PO Tracking" tab with:
    - Relief bucket distribution bar chart
    - Relief confidence pie chart
    - Vendor OTIF histogram
    - Critical gaps table (backorders without PO or unreliable vendors)
    - Gantt-style timeline visualization (next 60 days)
    - Detailed relief schedule table
- Relief data automatically filters with existing backorder page filters

---

#### 2.7.2 At-Risk Stockout Prediction (Week 2 - PRIORITY 2)

**Objectives**:
- Identify items likely to go on backorder BEFORE it happens
- Calculate safety stock and reorder points per SKU
- Predict "Days Until Stockout" based on current inventory and demand
- Proactive alerts to prevent backorders

**Core Features**:
```
‚úì Demand Calculation
  - Daily demand rate (30/60/90 day rolling averages)
  - Demand standard deviation (for safety stock)
  - Demand trend detection (growing/stable/declining)

‚úì Safety Stock & Reorder Point
  - Safety Stock = Z-score √ó ‚àö(Avg Lead Time) √ó StdDev(Daily Demand)
  - Reorder Point = (Daily Demand √ó Lead Time) + Safety Stock
  - Service level target: 95% (Z-score = 1.65)

‚úì Stockout Risk Scoring
  - Days Until Stockout = Current Stock / Daily Demand
  - Risk Levels:
    - Critical (0-7 days): Red flag
    - High (7-14 days): Orange flag
    - Moderate (14-30 days): Yellow flag
  - Factor in open PO coverage and vendor reliability

‚úì At-Risk Dashboard
  - Filter by risk level, category, SKU
  - Sort by days until stockout
  - Show recommended actions
```

**Technical Implementation**:
```python
# New module: stockout_prediction.py
def predict_stockout_risk(inventory_df, deliveries_df, vendor_pos_df, vendor_performance_df):
    """
    Identify SKUs at risk of stockout

    Calculates:
    - Daily demand (multiple time windows)
    - Demand variability
    - Safety stock
    - Reorder point
    - Days until stockout
    - PO coverage gap analysis
    - Risk score (0-100)

    Returns: DataFrame sorted by days_until_stockout
    """
```

**New Tab**: "‚ö†Ô∏è At-Risk Stockout Prediction"

**Tasks**:
- [ ] Create `stockout_prediction.py` module
- [ ] Implement daily demand calculation from deliveries
- [ ] Calculate safety stock using statistical methods
- [ ] Compute reorder points per SKU
- [ ] Build stockout risk scoring algorithm
- [ ] Create "At-Risk Stockout" tab
- [ ] Add alerts to overview page for critical items

---

#### 2.7.3 Enhanced Priority Scoring (Week 3 - PRIORITY 3)

**Objectives**:
- Multi-factor backorder prioritization
- Integrate vendor reliability, days until relief, customer value
- More accurate priority ranking for action planning

**Enhanced Priority Formula**:
```python
Priority Score = (
    Age (20%) √ó Normalized Age +
    Quantity (15%) √ó Normalized Qty +
    Vendor Reliability (20%) √ó (1 - Vendor OTIF%) +
    Days Until Relief (25%) √ó Normalized Days +
    Customer Value (10%) √ó Customer Tier +
    Product Margin (10%) √ó Margin %
) √ó 100
```

**Vendor Reliability Scoring**:
- No PO: 100 (highest priority)
- PO from vendor <75% OTIF: 80
- PO from vendor 75-90% OTIF: 50
- PO from vendor >90% OTIF: 20

**Days Until Relief Scoring**:
- No PO: 100
- Relief >60 days: 80
- Relief 30-60 days: 60
- Relief 7-30 days: 40
- Relief <7 days: 20

**Tasks**:
- [ ] Update `calculate_priority_score()` in backorder_page.py
- [ ] Add vendor reliability factor
- [ ] Add days until relief factor
- [ ] Implement customer value weighting (if data available)
- [ ] Update priority display in tables
- [ ] Adjust thresholds based on user feedback

---

#### 2.7.4 Backorder Root Cause Analysis (Week 3 - PRIORITY 4)

**Objectives**:
- Categorize each backorder by root cause
- Identify systemic issues (e.g., poor forecasting, vendor delays)
- Provide actionable recommendations per category

**Root Cause Categories**:
```
1. Insufficient PO Coverage
   - Backorder exists but NO open PO for SKU
   - Action: Create PO immediately

2. Vendor Delay
   - PO exists but vendor late vs expected delivery
   - Action: Escalate with vendor, consider backup

3. Demand Spike
   - Recent demand >50% above historical avg
   - Action: Review forecast, increase safety stock

4. Poor Forecasting
   - SKU has recurring backorders (3+ in 6 months)
   - Action: Adjust reorder point, review demand model

5. Long Vendor Lead Time
   - Vendor lead time >60 days
   - Action: Find faster supplier, increase order frequency

6. Safety Stock Too Low
   - Stockout despite PO coverage (demand variability issue)
   - Action: Recalculate safety stock with higher service level
```

**Visualization**:
- Root cause pie chart
- Top 10 SKUs by root cause category
- Vendor contribution to each root cause

**New Section**: "üîç Root Cause Analysis" (expander in Overview tab)

**Tasks**:
- [ ] Implement root cause categorization logic
- [ ] Create pie chart visualization
- [ ] Add root cause column to backorder tables
- [ ] Generate recommended actions per category
- [ ] Track root cause trends over time

---

#### 2.7.5 Demand-Based Insights (Week 4 - PRIORITY 5)

**Objectives**:
- Calculate backorder impact using demand metrics
- Customer impact scoring
- SKU criticality assessment

**New Calculations**:
```python
# Demand Coverage Gap
Days of Demand Backordered = Backorder Qty / Daily Demand
Lost Sales Risk = Days on Backorder √ó Daily Demand √ó Cancel Probability

# Customer Impact Score
Customer Impact = (
    Total Demand (90 days) +
    Number SKUs on Backorder +
    Total Days on Backorder
)

# SKU Criticality
SKU Criticality = (
    Number Customers Affected +
    Order Frequency (orders/month) +
    Demand Trend Coefficient
)
```

**New Metrics**:
- "Customer-Days Lost" (sum of customers √ó days on backorder)
- "Backorder as % of Monthly Demand"
- "Customers with Multiple Backorders"

**Tasks**:
- [ ] Implement demand-based calculations
- [ ] Add customer impact scoring
- [ ] Create SKU criticality ranking
- [ ] Add new metrics to KPI row
- [ ] Create customer impact table

---

#### 2.7.6 Vendor Performance Impact (Week 4 - PRIORITY 6)

**Objectives**:
- Cross-reference backorders with vendor performance
- Identify vendors causing most backorder pain
- Alternative vendor recommendations

**Vendor Backorder Analytics**:
```python
Vendor Backorder Score = (
    Count of backorders linked to vendor's late POs +
    Total units on backorder due to vendor +
    Average days late per vendor
)
```

**Features**:
- "Top 5 Vendors Causing Backorders" table
- "Backorder Units by Vendor" bar chart
- "Average Vendor Delay Days" comparison
- Alternative vendor suggestions with better OTIF

**Tasks**:
- [ ] Calculate vendor contribution to backorders
- [ ] Create vendor backorder scorecards
- [ ] Build alternative vendor recommendation engine
- [ ] Add vendor performance section to backorder page
- [ ] Link to vendor page for drill-down

---

### Implementation Roadmap

**Week 1: PO Relief Integration** ‚≠ê START HERE
```
Day 1-2: Create backorder_relief_analysis.py module
Day 3-4: Implement PO matching and vendor-adjusted dates
Day 5: Build Relief Timeline tab and visualizations
Day 6: Add new metrics to overview
Day 7: Testing and refinement
```

**Week 2: At-Risk Stockout Prediction**
```
Day 1-2: Create stockout_prediction.py module
Day 3-4: Implement demand calculations and safety stock
Day 5: Build At-Risk Stockout tab
Day 6-7: Add alerts and integrate with backorder page
```

**Week 3: Enhanced Prioritization & Root Cause**
```
Day 1-2: Update priority scoring algorithm
Day 3-4: Implement root cause categorization
Day 5: Create root cause visualizations
Day 6-7: Testing and user feedback
```

**Week 4: Demand Insights & Vendor Impact**
```
Day 1-3: Implement demand-based calculations
Day 4-5: Build vendor backorder analytics
Day 6-7: Final integration and polish
```

---

### Success Metrics

**Module Completion Criteria**:
- [ ] PO relief dates calculated for all backorders with vendor adjustment
- [ ] At-risk stockout prediction dashboard operational
- [ ] Enhanced priority scoring deployed
- [ ] Root cause analysis categorizing 100% of backorders
- [ ] New KPI metrics integrated into overview
- [ ] Unit tests for relief calculation (>80% coverage)
- [ ] User documentation and training materials

**Business Impact KPIs**:
- **Backorder Visibility**: 100% of backorders show expected relief date
- **Proactive Prevention**: Identify at-risk items 7-30 days before stockout
- **Faster Resolution**: Reduce average days on backorder by 20%
- **Better Prioritization**: Top 20% priority items aligned with business impact
- **Vendor Accountability**: Track vendor contribution to backorder issues

---

### 2.8 Demand Forecasting Module (Priority: MEDIUM)
**Status**: Placeholder exists, needs full implementation

**Objectives**:
- Forecast future demand by SKU
- Support inventory planning
- Identify seasonal trends
- Enable proactive procurement

**Data Integration**:
- Primary: ORDERS.csv, DELIVERIES.csv (historical demand)
- Supporting: Master Data.csv (product groupings)
- Links to: Inventory Module (planning), Inbound Module (procurement)

**Key Features**:
```
‚ñ° Historical demand analysis
‚ñ° Trend and seasonality detection
‚ñ° Statistical forecasting (moving average, exponential smoothing)
‚ñ° ML-based forecasting (optional)
‚ñ° Forecast accuracy tracking
‚ñ° Demand variability metrics
‚ñ° New product ramp forecasting
‚ñ° Promotional impact modeling
```

**Technical Tasks**:
- [ ] Build historical demand aggregation pipeline
- [ ] Implement basic forecasting algorithms
- [ ] Create forecast visualization page
- [ ] Add forecast vs actual comparison
- [ ] Integrate forecast into inventory planning
- [ ] Build forecast accuracy dashboard

---

**TBD - Future Enhancement: Hybrid Forecasting Approach**

**Objectives**:
Provide users with flexible forecasting options to balance ease-of-use, accuracy, and business logic through a dual-mode forecasting system.

**Forecast Mode 1: Traditional Statistical Forecasting (Default)**
```
Primary approach for ease of implementation and analysis
- Time series decomposition (trend, seasonality, residual)
- Moving averages (simple, weighted, exponential)
- Exponential smoothing (Holt-Winters)
- ARIMA models for complex patterns
- Seasonal adjustment factors

Recommended Tools (Easiest to Implement):
- Python statsmodels library (ARIMA, Holt-Winters, seasonal decomposition)
- SciPy for trend analysis
- Pandas rolling/expanding windows for moving averages
- Prophet (Facebook) for automated time series forecasting with seasonality
- Simple exponential smoothing for baseline forecasts

Benefits:
- Quick to implement with minimal data requirements
- Interpretable results for stakeholders
- Widely accepted statistical methods
- Good for SKUs with stable demand patterns
```

**Forecast Mode 2: Deterministic with Statistical Layer (Toggle Option)**
```
Hybrid approach combining business logic with statistical refinement
- Base Layer: Deterministic business rules and known drivers
  - Promotional calendars and planned events
  - Product lifecycle stages (launch, growth, maturity, decline)
  - Customer order patterns and committed volumes
  - Market intelligence and external factors
  - Vendor lead times and order minimums

- Statistical Overlay Layer:
  - Error correction using historical forecast accuracy
  - Variance bands and confidence intervals
  - Demand smoothing to reduce noise
  - Outlier detection and adjustment
  - Bias correction (consistent over/under forecasting)
  - Seasonality adjustment on top of base forecast

Benefits:
- Incorporates business knowledge and planned activities
- More accurate for new products, promotions, lifecycle changes
- Provides confidence intervals for risk assessment
- Adjusts deterministic inputs with statistical reality
```

**Implementation Strategy**:
```python
# Future module structure
def generate_forecast(sku, mode='statistical'):
    """
    Main forecasting function with mode toggle

    Parameters:
    - sku: SKU identifier
    - mode: 'statistical' or 'deterministic_hybrid'
    """
    if mode == 'statistical':
        return statistical_forecast(sku)
    elif mode == 'deterministic_hybrid':
        base_forecast = deterministic_forecast(sku)
        return apply_statistical_layer(base_forecast, sku)

def statistical_forecast(sku):
    """Traditional statistical methods"""
    # Moving averages, exponential smoothing, ARIMA, Prophet

def deterministic_forecast(sku):
    """Business rule-based forecast"""
    # Promotions, lifecycle, committed orders, market intel

def apply_statistical_layer(base_forecast, sku):
    """Apply statistical corrections to deterministic forecast"""
    # Error correction, smoothing, confidence intervals, bias adjustment
```

**User Interface Toggle**:
```
‚îå‚îÄ Demand Forecast Settings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                 ‚îÇ
‚îÇ Forecast Mode:                                 ‚îÇ
‚îÇ ‚óã Statistical Forecast (Default)               ‚îÇ
‚îÇ   ‚îî‚îÄ Uses time series analysis and historical  ‚îÇ
‚îÇ      patterns. Best for stable demand SKUs.    ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ ‚óã Deterministic + Statistical Hybrid           ‚îÇ
‚îÇ   ‚îî‚îÄ Combines business rules with statistical  ‚îÇ
‚îÇ      refinement. Best for promotional items    ‚îÇ
‚îÇ      and new products.                         ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ Forecast Horizon: [90] days                    ‚îÇ
‚îÇ Confidence Level: [95]%                        ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ [Generate Forecast] [Export Results]           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Phase 1 Tasks (Statistical Mode)**:
- [ ] Implement moving average forecasting (7/30/90 day)
- [ ] Add exponential smoothing (single, double, triple)
- [ ] Integrate statsmodels for ARIMA
- [ ] Evaluate Prophet for automated forecasting
- [ ] Build forecast accuracy metrics (MAPE, RMSE, MAE)
- [ ] Create forecast visualization with confidence intervals

**Phase 2 Tasks (Deterministic Hybrid Mode)** - TBD:
- [ ] Define business rule inputs (promotions, lifecycle, etc.)
- [ ] Build deterministic forecast engine
- [ ] Implement statistical error correction layer
- [ ] Add bias detection and adjustment
- [ ] Create variance band calculation
- [ ] Build comparative analysis (statistical vs hybrid)
- [ ] User testing and refinement

**Open Questions for Future Discussion**:
- Which deterministic inputs are available? (promotions, customer commitments, market data)
- What is the relative weight of deterministic vs statistical components?
- How do we validate hybrid forecast accuracy vs pure statistical?
- Should we automatically recommend mode based on SKU characteristics?
- What are the governance rules for manual forecast overrides?

---

### 2.9 Budget Forecast & Tracking Module (Priority: MEDIUM)
**Status**: TBD - Future module for financial planning and variance analysis

**Objectives**:
- Track actual vs budgeted performance across inbound, outbound, and inventory
- Provide category-level budget visibility and variance analysis
- Enable proactive budget management and reforecasting
- Support financial planning with supply chain operational data
- Generate executive-ready financial reports

**Data Integration**:
- Primary: Budget forecast data (category-level inbound/outbound/inventory targets)
- Supporting: DELIVERIES.csv (outbound actuals), DOMESTIC INBOUND.csv (inbound actuals), INVENTORY.csv (inventory actuals)
- Links to: Executive Overview (budget health KPIs), Inventory Module (inventory value tracking), Vendor Module (inbound spend)

**Key Features**:
```
‚ñ° Budget Data Upload & Management
  - Upload budget forecasts by category (inbound, outbound, inventory)
  - Support monthly/quarterly/annual budget periods
  - Version control for budget revisions and reforecasts
  - Template export for budget data entry

‚ñ° Outbound Budget Tracking
  - Actual vs budget outbound volume/value by category
  - Month-to-date, quarter-to-date, year-to-date variance
  - Forecast to end-of-period (run rate projections)
  - Top categories over/under budget
  - Trend analysis: are we trending toward budget?

‚ñ° Inbound Budget Tracking
  - Actual vs budget inbound volume/value by category
  - Purchase order commitments vs budget (committed but not received)
  - Vendor spend analysis vs budget allocations
  - Forecast remaining budget by category
  - Alert on budget exhaustion risk

‚ñ° Inventory Budget Tracking
  - Actual vs target inventory levels by category
  - Inventory value vs budget (total and by category)
  - Variance analysis: over-stocked vs under-stocked categories
  - Inventory turns vs target
  - Days on hand vs target

‚ñ° Variance Analysis & Reporting
  - Variance decomposition (volume vs price vs mix)
  - Root cause categorization (demand spike, vendor delay, etc.)
  - Favorable vs unfavorable variance highlighting
  - Drill-down from category to SKU level
  - Executive summary of key variances

‚ñ° Budget Reforecast & Projections
  - Run rate projections to end of period
  - "What-if" scenario planning
  - Identify areas needing budget adjustments
  - Recommend reallocation opportunities
  - Full-year forecast updates based on actuals
```

**User Interface Design**:
```
‚îå‚îÄ Budget Forecast & Tracking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                 ‚îÇ
‚îÇ üìÖ Budget Period: [Q4 2025 ‚ñº]  Currency: [USD ‚ñº] ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üìä Budget Health Overview                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ             ‚îÇ Budget   ‚îÇ Actual   ‚îÇ Variance‚îÇ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÇ
‚îÇ ‚îÇ Outbound    ‚îÇ $2.5M    ‚îÇ $2.3M    ‚îÇ -8% ‚úì  ‚îÇ‚îÇ
‚îÇ ‚îÇ Inbound     ‚îÇ $1.8M    ‚îÇ $1.9M    ‚îÇ +6% ‚ö†  ‚îÇ‚îÇ
‚îÇ ‚îÇ Inventory   ‚îÇ $5.0M    ‚îÇ $5.4M    ‚îÇ +8% ‚ö†  ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üìà Tabs:                                        ‚îÇ
‚îÇ ‚îú‚îÄ Overview (Budget Health Dashboard)          ‚îÇ
‚îÇ ‚îú‚îÄ Outbound Tracking (Deliveries vs Budget)    ‚îÇ
‚îÇ ‚îú‚îÄ Inbound Tracking (PO Spend vs Budget)       ‚îÇ
‚îÇ ‚îú‚îÄ Inventory Tracking (Inventory Value vs Budget)‚îÇ
‚îÇ ‚îú‚îÄ Variance Analysis (Drill-down by Category)  ‚îÇ
‚îÇ ‚îú‚îÄ Reforecast & Projections                    ‚îÇ
‚îÇ ‚îî‚îÄ Budget Data Management (Upload/Edit)        ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üîç Category-Level Details (Example: Outbound)  ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ Category     ‚îÇ Budget  ‚îÇ Actual ‚îÇ Variance ‚îÇ ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ ‚îÇ Sunglasses   ‚îÇ $800K   ‚îÇ $750K  ‚îÇ -6% ‚úì   ‚îÇ ‚îÇ
‚îÇ ‚îÇ Optical      ‚îÇ $1.2M   ‚îÇ $1.1M  ‚îÇ -8% ‚úì   ‚îÇ ‚îÇ
‚îÇ ‚îÇ Accessories  ‚îÇ $500K   ‚îÇ $450K  ‚îÇ -10% ‚úì  ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üìâ Visualizations:                              ‚îÇ
‚îÇ ‚îú‚îÄ Budget vs Actual waterfall chart            ‚îÇ
‚îÇ ‚îú‚îÄ Variance heatmap by category                ‚îÇ
‚îÇ ‚îú‚îÄ Trend line: monthly actual vs budget        ‚îÇ
‚îÇ ‚îú‚îÄ Run rate projection to end of period        ‚îÇ
‚îÇ ‚îî‚îÄ Top 10 favorable/unfavorable variances      ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ üì• Export Options:                              ‚îÇ
‚îÇ [Excel Export] [PDF Report] [Budget Template]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Budget Data Structure**:
```python
# Budget forecast CSV format (to be uploaded by user)
# Columns:
- budget_period (e.g., "2025-Q4", "2025-11", "2025")
- category (e.g., "Sunglasses", "Optical Frames", "Lenses")
- budget_type ("inbound", "outbound", "inventory")
- budget_value (numeric, USD or EUR)
- budget_volume (optional, units)
- notes (optional, text)

# Example:
budget_period,category,budget_type,budget_value,budget_volume,notes
2025-Q4,Sunglasses,outbound,800000,50000,Holiday season target
2025-Q4,Sunglasses,inbound,600000,45000,Vendor commitments
2025-Q4,Sunglasses,inventory,1200000,75000,Target end-of-quarter stock
```

**Key Metrics & KPIs**:
```
Outbound Metrics:
- Outbound Actual vs Budget ($, %)
- Outbound Volume vs Budget (units, %)
- Outbound Run Rate (projected end-of-period based on current pace)
- Top Categories Over/Under Budget
- Favorable Variance % (budget beating)

Inbound Metrics:
- Inbound Spend Actual vs Budget ($, %)
- Committed PO Spend (on order but not received)
- Remaining Budget Available (budget - actual - committed)
- Budget Utilization % (actual + committed / budget)
- Days Until Budget Exhaustion (if over-pacing)

Inventory Metrics:
- Inventory Value vs Target ($, %)
- Inventory Value Variance by Category
- Over-Stock Value (inventory > target)
- Under-Stock Value (inventory < target)
- Inventory Turns Actual vs Target
- Days on Hand Actual vs Target

Cross-Cutting Metrics:
- Overall Budget Health Score (composite 0-100)
- Variance Trend (improving/deteriorating)
- Forecast Accuracy (budget vs actual over time)
- Reforecast Confidence Level
```

**Technical Implementation**:
```python
# New module: budget_tracking.py

def load_budget_data(budget_csv_path):
    """Load budget forecast data from CSV"""
    # Returns DataFrame with budget targets by period/category/type

def calculate_outbound_variance(budget_df, deliveries_df, period, category=None):
    """
    Calculate outbound actual vs budget
    - Aggregate deliveries by category for period
    - Compare to budget targets
    - Return variance ($, %, favorable/unfavorable)
    """

def calculate_inbound_variance(budget_df, vendor_pos_df, inbound_df, period, category=None):
    """
    Calculate inbound actual vs budget
    - Aggregate receipts + committed POs by category
    - Compare to budget targets
    - Calculate remaining budget available
    """

def calculate_inventory_variance(budget_df, inventory_df, period, category=None):
    """
    Calculate inventory actual vs budget
    - Current inventory value by category
    - Compare to target inventory levels
    - Identify over/under stock categories
    """

def generate_variance_report(budget_df, actuals_df, budget_type, period):
    """
    Generate comprehensive variance analysis
    - Variance by category
    - Favorable vs unfavorable breakdown
    - Trend analysis
    - Drill-down to SKU level
    """

def project_run_rate(actuals_df, period, days_remaining):
    """
    Project end-of-period performance based on current run rate
    - Calculate daily/weekly run rate
    - Extrapolate to end of period
    - Return projected vs budget variance
    """

# New page: pages/budget_page.py
def render_budget_page(budget_data, deliveries_df, vendor_pos_df, inventory_df):
    """
    Main budget tracking dashboard
    Tabs:
    - Overview (health scorecard)
    - Outbound Tracking
    - Inbound Tracking
    - Inventory Tracking
    - Variance Analysis
    - Reforecast & Projections
    - Budget Data Management
    """
```

**Visualization Features**:
```
1. Budget Health Dashboard (Overview Tab)
   - KPI cards: Budget, Actual, Variance for each type
   - Traffic light indicators (Green/Yellow/Red)
   - Trend sparklines (improving/deteriorating)

2. Waterfall Chart (Variance Analysis)
   - Start with budget
   - Show positive/negative variances by category
   - End with actual
   - Clearly show favorable (green) vs unfavorable (red)

3. Heatmap (Category Performance)
   - Rows: Categories
   - Columns: Budget types (Inbound, Outbound, Inventory)
   - Color: Variance % (green = favorable, red = unfavorable)

4. Trend Chart (Month-over-Month)
   - Line chart: Budget vs Actual over time
   - Show if gap is widening or narrowing
   - Add run rate projection line

5. Top 10 Variances (Table + Bar Chart)
   - Top 10 favorable variances (beating budget)
   - Top 10 unfavorable variances (missing budget)
   - Sortable by $ variance and % variance
```

**Excel Export Specifications**:
```
Budget Variance Report.xlsx

Sheet 1: Executive Summary
- Budget period, currency, report date
- Overall variance summary table (inbound/outbound/inventory)
- Key highlights and alerts

Sheet 2: Outbound Detail
- Category-level outbound budget vs actual
- Columns: Category, Budget, Actual, Variance ($), Variance (%), Status

Sheet 3: Inbound Detail
- Category-level inbound budget vs actual
- Includes committed PO spend
- Remaining budget available by category

Sheet 4: Inventory Detail
- Category-level inventory value vs target
- Over/under stock analysis
- Inventory turns and DOH vs target

Sheet 5: Variance Analysis
- Drill-down to SKU level for top variances
- Root cause notes (manual entry or auto-generated)

Sheet 6: Run Rate Projections
- Current pace analysis
- Projected end-of-period performance
- Reforecast recommendations
```

**Integration Points**:
```
1. Executive Overview Module
   - Add budget health KPIs (Red/Yellow/Green indicators)
   - Alert on significant budget variances (>10%)
   - Link to budget page for drill-down

2. Inventory Module
   - Show target inventory levels from budget
   - Highlight categories over/under target
   - Link to budget variance analysis

3. Vendor Module
   - Show remaining budget by vendor
   - Alert when vendor spend approaching budget limit
   - Track vendor spend vs allocated budget

4. Demand Forecasting Module (Future)
   - Use budget targets as demand planning input
   - Reforecast budget based on updated demand forecast
   - Close the loop: demand ‚Üí budget ‚Üí actuals ‚Üí reforecast
```

**Business Rules** (to be added to business_rules.py):
```python
BUDGET_RULES = {
    "variance_thresholds": {
        "favorable": -5,        # >5% under budget = favorable (green)
        "acceptable": 5,        # ¬±5% = on track (yellow)
        "unfavorable": 5        # >5% over budget = unfavorable (red)
    },
    "alert_thresholds": {
        "critical_variance": 15,      # >15% variance triggers alert
        "budget_utilization": 90,     # >90% budget used triggers alert
        "inventory_over_target": 20   # >20% over inventory target = alert
    },
    "reforecast_triggers": {
        "variance_threshold": 10,     # >10% variance for 2+ months = reforecast needed
        "trend_deterioration": 5      # Variance worsening by >5% month-over-month
    },
    "reporting_periods": {
        "supported": ["monthly", "quarterly", "annual"],
        "default": "quarterly"
    }
}
```

**Phase 1 Tasks - Foundation** (Priority: MEDIUM):
- [ ] Create budget data template (CSV format)
- [ ] Build budget data loader (`load_budget_data()`)
- [ ] Implement budget upload page with validation
- [ ] Create budget data storage structure (session state or file-based)
- [ ] Add budget navigation to main dashboard

**Phase 2 Tasks - Core Tracking** (Priority: HIGH):
- [ ] Implement outbound variance calculation
- [ ] Implement inbound variance calculation (actuals + committed POs)
- [ ] Implement inventory variance calculation
- [ ] Create budget overview dashboard (KPI cards)
- [ ] Build category-level variance tables

**Phase 3 Tasks - Visualizations** (Priority: HIGH):
- [ ] Create waterfall chart for variance analysis
- [ ] Build variance heatmap by category
- [ ] Add trend charts (budget vs actual over time)
- [ ] Implement run rate projection visualizations
- [ ] Create top 10 variance bar charts

**Phase 4 Tasks - Advanced Features** (Priority: MEDIUM):
- [ ] Build comprehensive Excel export (6-sheet workbook)
- [ ] Add PDF report generation
- [ ] Implement reforecast projections
- [ ] Create "what-if" scenario planning tool
- [ ] Add drill-down from category to SKU level
- [ ] Integrate budget alerts into Executive Overview

**Phase 5 Tasks - Integration** (Priority: LOW):
- [ ] Link budget targets to inventory planning
- [ ] Add vendor budget tracking to vendor page
- [ ] Integrate with demand forecasting (future)
- [ ] Build automated budget vs forecast reconciliation

**Open Questions for Future Discussion**:
- What is the budget planning cycle? (monthly, quarterly, annual)
- How are budgets set at category level? (top-down, bottom-up, hybrid)
- Should we support budget revisions and version control?
- Do we need user roles for budget data entry vs read-only access?
- What is the approval workflow for budget reforecasts?
- Should we track budget by customer segment or geography?
- How do we handle currency conversion for multi-currency budgets?

**Success Metrics**:

**Module Completion Criteria**:
- [ ] Budget data upload and validation operational
- [ ] All three budget types tracked (inbound, outbound, inventory)
- [ ] Category-level variance analysis functional
- [ ] Excel export with all 6 sheets implemented
- [ ] Integration with Executive Overview complete
- [ ] Unit tests for variance calculations (>80% coverage)
- [ ] User documentation and training materials

**Business Impact KPIs**:
- **Budget Visibility**: 100% of categories tracked against budget
- **Proactive Alerts**: Identify budget risks 30+ days before period end
- **Forecast Accuracy**: <10% average variance between budget and actuals
- **Reforecast Speed**: Generate updated forecasts in <5 minutes
- **Executive Adoption**: Budget reports used in monthly/quarterly business reviews

---

### 2.10 Executive Overview Module (Priority: HIGH)
**Status**: Basic implementation exists, needs enhancement

**Objectives**:
- Single-pane-of-glass view of supply chain health
- Key KPIs across all modules
- Exception highlighting and alerts
- Executive-level reporting

**Data Integration**:
- Aggregated data from all modules
- Cross-module insights

**Key Features**:
```
‚úì High-level KPI cards
‚úì Basic performance charts
‚ñ° Supply chain health score
‚ñ° Critical alerts dashboard
‚ñ° Executive summary reports
‚ñ° Trend analysis across modules
‚ñ° Custom KPI builder
‚ñ° Goal tracking and variance
```

**Technical Tasks**:
- [ ] Enhance overview page with health scoring
- [ ] Implement cross-module alerts
- [ ] Create executive report generator
- [ ] Build customizable KPI dashboard
- [ ] Add goal-setting and tracking

---

## Phase 2.5: Performance Optimization & Refactoring (CRITICAL CHECKPOINT)

**Timing**: Execute after completing 5+ modules but BEFORE Phase 3 integration
**Rationale**: Optimize foundation before building complex integrations on top

### Why Optimize Now?

As the platform grows with multiple modules, performance degradation is inevitable without proactive optimization. This checkpoint ensures:
- Fast user experience as data volume grows
- Solid foundation for Phase 3 integrations
- Technical debt doesn't compound
- Scalability is built-in from the start

---

### 2.5.1 Performance Audit & Baseline (Week 1)

**Objectives**:
- Establish performance baselines for all existing modules
- Identify performance bottlenecks using profiling tools
- Document current load times and resource usage
- Create performance testing suite

**Key Metrics to Measure**:
```
Load Time Metrics:
- Dashboard initial load time (target: <5 seconds)
- Page navigation time (target: <2 seconds)
- Data refresh time (target: <3 seconds)
- Filter/search response time (target: <1 second)
- Export generation time (target: <10 seconds for 10K rows)

Resource Metrics:
- Memory usage (baseline vs peak)
- CPU utilization during operations
- Data loading time by file size
- Cache hit rates
- Database query times (if applicable)
```

**Performance Testing Tools**:
```python
# Use Python profiling tools
import cProfile
import time
from memory_profiler import profile

# Create performance_profiler.py module
def profile_data_loading():
    """Profile all data loading operations"""

def profile_page_rendering():
    """Profile Streamlit page render times"""

def profile_calculations():
    """Profile expensive calculations (DIO, variance, forecasts)"""
```

**Deliverables**:
- [ ] Performance baseline report (all modules)
- [ ] Bottleneck identification document
- [ ] Performance test suite (`tests/test_performance.py`)
- [ ] Load time dashboard (internal tool)

---

### 2.5.2 Data Loading & Caching Optimization (Week 2 - HIGH PRIORITY)

**Problem**: Multiple modules load the same data repeatedly, causing slow page loads

**Solutions**:

**1. Implement Global Caching Strategy**
```python
# Optimize data_loader.py with aggressive caching
import streamlit as st
from functools import lru_cache

@st.cache_data(ttl=3600, show_spinner="Loading data...")
def load_all_data():
    """Load all data once and cache for 1 hour"""
    return {
        'orders': load_orders(),
        'deliveries': load_deliveries(),
        'inventory': load_inventory(),
        'master_data': load_master_data(),
        'vendor_pos': load_vendor_pos(),
        'inbound': load_inbound(),
        'alternate_codes': load_alternate_codes()
    }

@st.cache_data(ttl=3600)
def load_processed_data():
    """Cache expensive processed data"""
    raw_data = load_all_data()
    return {
        'backorder_relief': calculate_backorder_relief(raw_data),
        'inventory_dio': calculate_inventory_dio(raw_data),
        'vendor_performance': calculate_vendor_performance(raw_data)
    }
```

**2. Lazy Loading for Large Datasets**
```python
# Only load data when needed, not on every page
def load_data_on_demand(data_type):
    """Load specific dataset only when requested"""
    if data_type not in st.session_state:
        st.session_state[data_type] = load_dataset(data_type)
    return st.session_state[data_type]
```

**3. Incremental Data Loading**
```python
# For very large files, load in chunks
def load_large_csv_incremental(file_path, chunksize=10000):
    """Load large CSV in chunks with progress bar"""
    chunks = []
    total_rows = sum(1 for _ in open(file_path)) - 1
    progress_bar = st.progress(0)

    for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunksize)):
        chunks.append(chunk)
        progress_bar.progress(min((i * chunksize) / total_rows, 1.0))

    return pd.concat(chunks, ignore_index=True)
```

**4. Optimize Data Types**
```python
# Reduce memory usage with proper data types
def optimize_dtypes(df):
    """Convert columns to optimal data types"""
    # Convert object to category for low-cardinality columns
    for col in df.select_dtypes(include=['object']):
        if df[col].nunique() / len(df) < 0.5:
            df[col] = df[col].astype('category')

    # Downcast numeric columns
    df = df.apply(pd.to_numeric, errors='ignore', downcast='integer')
    df = df.apply(pd.to_numeric, errors='ignore', downcast='float')

    return df
```

**Tasks**:
- [ ] Implement global caching in `data_loader.py`
- [ ] Add lazy loading for optional datasets
- [ ] Optimize data types for all DataFrames
- [ ] Implement incremental loading for files >50MB
- [ ] Add cache invalidation logic (user-triggered refresh)
- [ ] Test cache performance improvements

**Expected Improvement**: 50-70% reduction in initial load time

---

### 2.5.3 Calculation & Aggregation Optimization (Week 3 - HIGH PRIORITY)

**Problem**: Expensive calculations (DIO, variance, forecasts) run on every page load or filter change

**Solutions**:

**1. Cache Expensive Calculations**
```python
# Cache calculation results
@st.cache_data(ttl=3600)
def calculate_inventory_dio_cached(inventory_df, deliveries_df):
    """Cache DIO calculations for 1 hour"""
    return calculate_inventory_dio(inventory_df, deliveries_df)

@st.cache_data(ttl=3600)
def calculate_backorder_relief_cached(backorder_df, vendor_pos_df, vendor_perf_df):
    """Cache backorder relief calculations"""
    return calculate_backorder_relief_dates(backorder_df, vendor_pos_df, vendor_perf_df)
```

**2. Precompute Common Aggregations**
```python
# Precompute aggregations during data loading
def precompute_aggregations(data):
    """Precompute common aggregations to avoid recalculating"""
    return {
        'inventory_by_category': data['inventory'].groupby('category').agg({
            'on_hand_qty': 'sum',
            'inventory_value': 'sum'
        }),
        'deliveries_by_month': data['deliveries'].groupby(
            pd.Grouper(key='delivery_date', freq='M')
        )['qty'].sum(),
        'backorders_by_customer': data['orders'].groupby('customer')['backorder_qty'].sum()
    }
```

**3. Use Vectorized Operations (Avoid Loops)**
```python
# BAD: Row-by-row iteration
for index, row in df.iterrows():
    df.loc[index, 'dio'] = calculate_dio(row)

# GOOD: Vectorized operation
df['dio'] = (df['on_hand_qty'] / df['daily_demand']).fillna(0)
```

**4. Optimize Pandas Operations**
```python
# Use efficient Pandas methods
# BAD: Multiple operations
df = df[df['qty'] > 0]
df = df[df['status'] == 'open']
df = df.sort_values('date')

# GOOD: Chain operations
df = (df[df['qty'] > 0]
      .query("status == 'open'")
      .sort_values('date'))

# Use eval() for complex calculations
df['result'] = df.eval('(on_hand_qty * price) / demand')
```

**Tasks**:
- [ ] Cache all expensive calculations (DIO, variance, relief dates)
- [ ] Precompute common aggregations in `data_loader.py`
- [ ] Refactor loops to vectorized operations
- [ ] Optimize Pandas operations across all modules
- [ ] Profile calculation performance before/after

**Expected Improvement**: 40-60% reduction in calculation time

---

### 2.5.4 UI Rendering & Streamlit Optimization (Week 4 - HIGH PRIORITY)

**Problem**: Large tables, charts, and complex layouts cause slow page rendering

**Solutions**:

**1. Implement Pagination for Large Tables**
```python
# Paginate tables instead of showing all rows
def render_paginated_table(df, rows_per_page=50):
    """Render table with pagination"""
    total_pages = len(df) // rows_per_page + 1
    page = st.number_input('Page', min_value=1, max_value=total_pages, value=1)

    start_idx = (page - 1) * rows_per_page
    end_idx = start_idx + rows_per_page

    st.dataframe(df.iloc[start_idx:end_idx])
    st.caption(f"Showing {start_idx+1}-{min(end_idx, len(df))} of {len(df)} rows")
```

**2. Lazy Loading for Charts**
```python
# Only render charts when expanded
with st.expander("üìä Advanced Analytics", expanded=False):
    # Chart only renders when user expands
    st.plotly_chart(create_complex_chart(data))
```

**3. Optimize Plotly Charts**
```python
# Reduce chart complexity for better performance
def create_optimized_chart(df):
    # Limit data points for scatter plots
    if len(df) > 1000:
        df_sample = df.sample(1000)
    else:
        df_sample = df

    fig = px.scatter(df_sample, x='x', y='y')

    # Disable hover for large datasets
    if len(df) > 5000:
        fig.update_traces(hoverinfo='skip')

    return fig
```

**4. Use st.empty() for Dynamic Updates**
```python
# Use containers for efficient updates
placeholder = st.empty()

# Update without re-rendering entire page
with placeholder.container():
    st.metric("KPI", value)
```

**5. Minimize Widget State**
```python
# Use session state efficiently
if 'filters' not in st.session_state:
    st.session_state.filters = default_filters()

# Avoid recreating widgets unnecessarily
category_filter = st.session_state.filters.get('category', 'All')
```

**Tasks**:
- [ ] Implement pagination for all tables >100 rows
- [ ] Use expanders for advanced charts/analytics
- [ ] Optimize Plotly charts (reduce points, disable hover)
- [ ] Refactor dynamic updates to use st.empty()
- [ ] Minimize session state usage
- [ ] Add loading spinners for async operations

**Expected Improvement**: 30-50% reduction in page render time

---

### 2.5.5 Code Refactoring & Architecture Cleanup (Week 5 - MEDIUM PRIORITY)

**Objectives**:
- Eliminate code duplication across modules
- Standardize data processing patterns
- Improve code maintainability
- Create reusable components

**Refactoring Tasks**:

**1. Create Shared Utilities Module**
```python
# utils/data_processing.py
def aggregate_by_category(df, value_col):
    """Standard aggregation by category"""

def calculate_variance(actual, budget):
    """Standard variance calculation"""

def format_currency(value, currency='USD'):
    """Standard currency formatting"""

# utils/ui_components.py
def render_kpi_card(title, value, delta, format='number'):
    """Reusable KPI card component"""

def render_filter_sidebar(filters_config):
    """Standard filter sidebar"""

def render_export_buttons(df, filename_base):
    """Standard export button group"""
```

**2. Standardize Page Structure**
```python
# Create page template in ui_components.py
class PageTemplate:
    def __init__(self, title, icon):
        self.title = title
        self.icon = icon

    def render(self, content_func):
        """Standard page rendering structure"""
        st.title(f"{self.icon} {self.title}")

        # Standard sidebar
        with st.sidebar:
            self.render_filters()

        # Standard tabs
        self.render_tabs(content_func)

        # Standard footer
        self.render_footer()
```

**3. Extract Common Business Logic**
```python
# Create business_logic.py module
class InventoryAnalyzer:
    """Reusable inventory analysis logic"""
    def calculate_dio(self, inventory, demand):
        pass

    def classify_movement(self, dio):
        pass

class VarianceAnalyzer:
    """Reusable variance analysis logic"""
    def calculate_variance(self, actual, budget):
        pass

    def classify_variance(self, variance_pct):
        pass
```

**Tasks**:
- [ ] Create `utils/data_processing.py` with shared functions
- [ ] Create `utils/ui_components.py` with reusable components
- [ ] Extract business logic to `business_logic.py`
- [ ] Refactor all pages to use shared utilities
- [ ] Remove duplicate code across modules
- [ ] Update documentation with new architecture

**Expected Improvement**: 30-40% reduction in codebase size, easier maintenance

---

### 2.5.6 Database Migration Planning (Week 6 - OPTIONAL)

**When to Consider**: If CSV files exceed 100MB or require real-time updates

**Database Options**:
```
1. SQLite (Simplest)
   - Pros: File-based, no server needed, SQL queries
   - Cons: Limited concurrency, file locking issues
   - Best for: <1GB data, single user

2. PostgreSQL (Recommended)
   - Pros: ACID compliance, excellent performance, concurrent users
   - Cons: Requires server setup
   - Best for: >1GB data, multiple users, production use

3. DuckDB (Modern Alternative)
   - Pros: Embedded, fast analytics, Parquet support
   - Cons: Newer, less ecosystem support
   - Best for: Analytical workloads, columnar data
```

**Migration Strategy**:
```python
# Create db_loader.py for database operations
from sqlalchemy import create_engine
import pandas as pd

class DatabaseLoader:
    def __init__(self, connection_string):
        self.engine = create_engine(connection_string)

    def load_orders(self, filters=None):
        """Load orders with SQL filtering"""
        query = "SELECT * FROM orders WHERE 1=1"
        if filters:
            query += self.build_where_clause(filters)
        return pd.read_sql(query, self.engine)

    def bulk_insert(self, df, table_name):
        """Efficient bulk insert"""
        df.to_sql(table_name, self.engine, if_exists='append',
                  index=False, method='multi', chunksize=1000)
```

**Tasks** (if database migration needed):
- [ ] Evaluate database options based on data size and users
- [ ] Design database schema
- [ ] Create migration scripts (CSV ‚Üí DB)
- [ ] Update data_loader.py to support DB
- [ ] Implement connection pooling
- [ ] Add database backup strategy
- [ ] Performance test DB vs CSV

**Expected Improvement**: 70-90% faster queries for large datasets

---

### 2.5.7 Performance Testing & Validation (Week 7 - CRITICAL)

**Objectives**:
- Validate all optimizations achieved target metrics
- Identify any remaining bottlenecks
- Document performance improvements
- Create ongoing monitoring

**Performance Test Suite**:
```python
# tests/test_performance.py
import pytest
import time

class TestPerformanceTargets:
    def test_dashboard_load_time(self):
        """Dashboard should load in <5 seconds"""
        start = time.time()
        load_dashboard()
        load_time = time.time() - start
        assert load_time < 5.0, f"Load time {load_time}s exceeds 5s target"

    def test_filter_response_time(self):
        """Filters should respond in <1 second"""
        start = time.time()
        apply_filters({'category': 'Sunglasses'})
        response_time = time.time() - start
        assert response_time < 1.0

    def test_export_time(self):
        """Exports should complete in <10 seconds for 10K rows"""
        df = create_test_dataframe(10000)
        start = time.time()
        export_to_excel(df)
        export_time = time.time() - start
        assert export_time < 10.0
```

**Performance Monitoring Dashboard**:
```python
# Create internal performance monitoring page
def render_performance_dashboard():
    st.title("üìä Performance Monitoring")

    metrics = {
        'Dashboard Load Time': measure_load_time(),
        'Memory Usage': measure_memory(),
        'Cache Hit Rate': measure_cache_hits(),
        'Avg Query Time': measure_query_time()
    }

    # Display metrics with targets
    cols = st.columns(4)
    for i, (metric, value) in enumerate(metrics.items()):
        with cols[i]:
            st.metric(metric, f"{value:.2f}s",
                     delta=f"{value - targets[metric]:.2f}s")
```

**Tasks**:
- [ ] Run comprehensive performance test suite
- [ ] Compare before/after optimization metrics
- [ ] Document performance improvements
- [ ] Create performance monitoring dashboard (internal)
- [ ] Set up performance regression alerts
- [ ] Update user documentation with performance expectations

**Success Criteria**:
- ‚úì Dashboard loads in <5 seconds (80% improvement target)
- ‚úì Page navigation in <2 seconds
- ‚úì Filter/search response in <1 second
- ‚úì Memory usage reduced by 40%+
- ‚úì All modules meet performance SLAs

---

### Phase 2.5 Summary & Go/No-Go Decision

**Before proceeding to Phase 3**, verify:
- [ ] All performance targets met
- [ ] Code refactoring complete (shared utilities implemented)
- [ ] Technical debt reduced significantly
- [ ] Performance monitoring in place
- [ ] User testing confirms improved responsiveness

**If targets not met**: Allocate additional optimization time before Phase 3

**Estimated Duration**: 6-7 weeks (can be parallelized with ongoing development)

**ROI**: Every week invested in optimization saves 3-4 weeks in Phase 3-4 debugging and rework

---

## Phase 3: Module Integration & Workflows

### 3.1 Inter-Module Data Flows
**Goal**: Enable modules to share data and trigger actions

**Integration Points**:
1. **Backorder ‚Üí Inbound**: Link backorders to expected PO receipts for ETA
2. **Inbound ‚Üí Inventory**: Auto-update inventory on receipt
3. **Inventory ‚Üí Backorder**: Auto-allocate stock to backorders
4. **Service Level ‚Üí Backorder**: Identify late orders that became backorders
5. **Forecast ‚Üí Inventory**: Feed forecast into replenishment planning
6. **Forecast ‚Üí Inbound**: Generate procurement recommendations

**Technical Approach**:
- Shared data models in `data_loader.py`
- Event system for cross-module triggers
- Centralized state management
- API layer for module communication

---

### 3.2 Workflow Automation
**Goal**: Automate common supply chain workflows

**Priority Workflows**:
1. **Backorder Resolution**
   - Detect incoming stock
   - Prioritize and allocate to backorders
   - Generate pick lists
   - Update customer ETA

2. **Stock-Out Prevention**
   - Monitor inventory vs forecast
   - Alert when approaching reorder point
   - Auto-generate procurement recommendations
   - Track PO until receipt

3. **Service Level Recovery**
   - Detect late orders
   - Identify root causes (inventory, supplier delay)
   - Recommend corrective actions
   - Track to resolution

**Technical Tasks**:
- [ ] Build workflow engine
- [ ] Create rule-based automation system
- [ ] Implement notification framework
- [ ] Build workflow monitoring dashboard

---

## Phase 4: Advanced Features

**‚ö†Ô∏è Performance Check-In**: Before adding advanced features, validate that Phase 2.5 optimizations are holding up under Phase 3 integrations. Run performance regression tests.

---

### 4.0 International Suppliers Expansion (Priority: MEDIUM - Phase 4+)

**‚ö†Ô∏è MAJOR ENHANCEMENT: Add Italy and China Suppliers**

**When to Implement**: After Phase 2.5 optimization and Phase 3 integrations are complete

**Scope**: Expand vendor and inbound modules to support international suppliers with different business logic, lead times, and data requirements.

**Current State**: Platform designed for **DOMESTIC SUPPLIERS ONLY**
**Future State**: Multi-region supplier support (Domestic, Italy, China)

**Key Differences by Supplier Region**:

| Dimension | Domestic (US) | Italy | China |
|-----------|---------------|-------|-------|
| Lead Time | 3-7 days | 15-30 days | 30-60 days |
| Shipping | Truck/Ground | Ocean/Air Freight | Ocean Freight |
| Currency | USD | EUR | CNY |
| OTIF Target | 95% | 85% | 80% |
| Customs | None | 3-5 day buffer | 5-7 day buffer |
| Incoterms | N/A | FOB/CIF/DDP | FOB/CIF/DDP |
| Complexity | Low | Medium | High |

**Implementation Tasks**:

**Phase 4.0.1: Data Model Extensions** (Week 1-2)
- [ ] Add `vendor_type` field to vendor master data ('domestic', 'italy', 'china')
- [ ] Add `incoterm` field to PO data (FOB, CIF, DDP, etc.)
- [ ] Add `customs_clearance_date` to inbound data
- [ ] Add `base_currency` field to vendor data
- [ ] Create ITALY_INBOUND.csv and CHINA_INBOUND.csv data loaders
- [ ] Add CUSTOMS_CLEARANCE.csv loader (optional)

**Phase 4.0.2: Business Rules by Vendor Type** (Week 2-3)
- [ ] Create separate VENDOR_RULES for each vendor type in `business_rules.py`
- [ ] Implement vendor-specific OTIF calculation (with/without customs buffer)
- [ ] Create vendor-specific lead time targets
- [ ] Add landed cost calculation (base price + freight + duty + fees)
- [ ] Currency conversion logic (EUR, CNY ‚Üí USD)

**Phase 4.0.3: UI Enhancements** (Week 3-4)
- [ ] Add "Vendor Type" filter (Domestic / Italy / China / All)
- [ ] Create separate vendor scorecards by type
- [ ] Add lead time breakdown visualization (Manufacturing ‚Üí Shipping ‚Üí Customs ‚Üí Delivery)
- [ ] Multi-currency display with conversion rates
- [ ] Landed cost breakdown view
- [ ] Container tracking integration (for ocean freight)

**Phase 4.0.4: Reporting & Analytics** (Week 5-6)
- [ ] Separate OTIF reports by vendor type
- [ ] Lead time variance by region
- [ ] Customs delay analysis (Italy/China only)
- [ ] Currency fluctuation impact on landed cost
- [ ] Port congestion impact (China only)
- [ ] Vendor comparison across regions

**New Data Requirements**:
```python
# Example international vendor PO structure
{
    "po_number": "PO-IT-001",
    "vendor_name": "Luxottica Italy",
    "vendor_type": "italy",  # NEW FIELD
    "sku": "123456",
    "order_qty": 1000,
    "unit_price": 45.50,
    "currency": "EUR",  # NEW FIELD
    "incoterm": "FOB",  # NEW FIELD
    "factory_ship_date": "2025-01-15",
    "port_arrival_date": "2025-01-25",  # NEW FIELD
    "customs_clearance_date": "2025-01-29",  # NEW FIELD
    "warehouse_delivery_date": "2025-01-31",
    "freight_cost": 500,  # NEW FIELD
    "duty_cost": 150,  # NEW FIELD
    "customs_fees": 50  # NEW FIELD
}
```

**New Metrics for International Suppliers**:
- **Total Lead Time Breakdown**: Manufacturing + Freight + Customs + Delivery
- **In-Transit Inventory Value**: Goods on ocean/air freight
- **Customs Clearance Time**: Avg days in customs by country
- **Landed Cost**: Base + Freight + Duty + Fees
- **Currency Variance Impact**: Price changes due to FX fluctuation
- **Port Congestion Factor**: Delay multiplier for China shipments

**Integration with Existing Modules**:

1. **Backorder Module**:
   - Adjust relief dates for international POs (longer lead times)
   - Factor in customs clearance time
   - Display freight status (in-transit, at port, in customs, delivered)

2. **Inventory Module**:
   - Track in-transit inventory separately
   - Landed cost vs base cost analysis
   - Adjust reorder points for longer lead times

3. **Budget Module** (if implemented):
   - Track budget by vendor region
   - Currency variance impact on budget
   - Duty/freight cost allocation

**Technical Architecture Changes**:
```python
# business_rules.py additions
VENDOR_TYPE_RULES = {
    "domestic": {
        "lead_time_target_days": 7,
        "otif_target_pct": 95,
        "currency": "USD",
        "customs_buffer_days": 0,
        "freight_mode": "truck"
    },
    "italy": {
        "lead_time_target_days": 25,
        "otif_target_pct": 85,
        "currency": "EUR",
        "customs_buffer_days": 4,
        "freight_mode": "ocean_air",
        "exchange_rate_source": "ECB_API"  # European Central Bank
    },
    "china": {
        "lead_time_target_days": 45,
        "otif_target_pct": 80,
        "currency": "CNY",
        "customs_buffer_days": 6,
        "freight_mode": "ocean",
        "port_congestion_factor": 1.15,  # 15% buffer for port delays
        "exchange_rate_source": "PBOC_API"  # People's Bank of China
    }
}

# Vendor-specific OTIF calculation
def calculate_otif_by_vendor_type(vendor_type, expected_date, actual_date):
    """
    Calculate OTIF with vendor-type-specific logic
    - Domestic: Strict (no buffer)
    - Italy: Allow customs buffer
    - China: Allow customs + port congestion buffer
    """
    rules = VENDOR_TYPE_RULES[vendor_type]
    buffer_days = rules["customs_buffer_days"]

    if vendor_type == "china":
        buffer_days *= rules.get("port_congestion_factor", 1.0)

    adjusted_expected_date = expected_date + timedelta(days=buffer_days)
    return actual_date <= adjusted_expected_date
```

**Success Criteria**:
- [ ] All three vendor types (Domestic, Italy, China) tracked in single dashboard
- [ ] Vendor-specific OTIF targets met (95% / 85% / 80%)
- [ ] Multi-currency support operational (USD, EUR, CNY)
- [ ] Landed cost calculation accurate (¬±2% variance)
- [ ] Customs delay visibility for international shipments
- [ ] User can filter/compare vendors across regions

**Estimated Effort**: 6 weeks (can be parallelized with other Phase 4 work)

**Business Value**:
- **Visibility**: Complete supply chain view (domestic + international)
- **Cost Control**: Landed cost tracking, currency variance monitoring
- **Risk Mitigation**: Identify customs delays, port congestion issues
- **Vendor Optimization**: Compare performance across regions
- **Planning**: Accurate lead times for international procurement

---

### 4.1 Real-Time Data Integration

**Performance Consideration**: Database connectivity and real-time updates must maintain responsiveness

**Implementation Guidelines**:
```python
# Use connection pooling to avoid overhead
from sqlalchemy.pool import QueuePool

engine = create_engine(
    connection_string,
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20
)

# Implement incremental refresh, not full reload
def refresh_data_incremental(last_updated):
    """Only fetch new/changed records since last update"""
    query = f"SELECT * FROM orders WHERE updated_at > '{last_updated}'"
    return pd.read_sql(query, engine)
```

**Features**:
- Database connectivity (SQL Server/PostgreSQL)
- Automated data refresh (incremental, not full)
- Change data capture (CDC) for real-time updates
- Real-time alerting with minimal performance impact
- Connection pooling and query optimization

**Performance Tasks**:
- [ ] Profile database query performance
- [ ] Implement connection pooling
- [ ] Optimize queries with indexes
- [ ] Cache frequent queries
- [ ] Monitor database load impact on UI

---

### 4.2 Advanced Analytics

**Performance Consideration**: ML models and complex analytics can be CPU-intensive

**Implementation Guidelines**:
```python
# Run expensive analytics asynchronously
import asyncio
from concurrent.futures import ThreadPoolExecutor

@st.cache_data(ttl=86400)  # Cache ML predictions for 24 hours
def run_demand_forecast_ml(sku_data):
    """Run ML forecast with caching"""
    return forecast_model.predict(sku_data)

# Use background processing for heavy computations
def run_analytics_background(data):
    """Run analytics in background thread"""
    with ThreadPoolExecutor(max_workers=4) as executor:
        future = executor.submit(expensive_calculation, data)
        return future.result()
```

**Features**:
- Machine learning models for demand forecasting (cached predictions)
- Anomaly detection across all modules (run periodically, not real-time)
- Optimization algorithms (inventory, allocation) with progress indicators
- Simulation and scenario planning (with performance warnings for large simulations)

**Performance Tasks**:
- [ ] Cache ML model predictions (24+ hour TTL)
- [ ] Run complex analytics in background threads
- [ ] Add progress indicators for long-running operations
- [ ] Limit simulation complexity based on data size
- [ ] Profile analytics performance impact

---

### 4.3 Collaboration Features

**Performance Consideration**: Comments, annotations, and user tracking should not slow down core functionality

**Implementation Guidelines**:
```python
# Store collaboration data separately from core data
# Use lazy loading for comments/annotations
def load_comments_on_demand(entity_id):
    """Only load comments when user expands comments section"""
    if f'comments_{entity_id}' not in st.session_state:
        st.session_state[f'comments_{entity_id}'] = fetch_comments(entity_id)
    return st.session_state[f'comments_{entity_id}']
```

**Features**:
- User roles and permissions (lightweight middleware)
- Comments and annotations (lazy-loaded)
- Shared reports and dashboards (cached)
- Task assignment and tracking (separate database table)

**Performance Tasks**:
- [ ] Lazy-load collaboration features
- [ ] Separate collaboration data from core analytics
- [ ] Cache user permissions
- [ ] Minimize collaboration data size

---

### 4.4 Mobile & API Access

**Performance Consideration**: Mobile devices have limited resources; API responses must be fast

**Implementation Guidelines**:
```python
# API responses should be lightweight and paginated
from fastapi import FastAPI, Query
from fastapi.responses import JSONResponse

app = FastAPI()

@app.get("/api/inventory")
async def get_inventory(
    category: str = Query(None),
    limit: int = Query(100, le=1000),
    offset: int = Query(0)
):
    """Paginated API endpoint"""
    data = query_inventory(category, limit, offset)
    return JSONResponse(content=data.to_dict('records'))

# Mobile-responsive UI with reduced data
def render_mobile_dashboard():
    """Simplified dashboard for mobile devices"""
    # Show only KPIs, no heavy charts
    # Lazy-load detailed views
```

**Features**:
- Mobile-responsive UI (simplified views, lazy-loaded charts)
- REST API for external integrations (paginated, cached)
- Mobile app for field operations (offline-capable)
- Webhook support for event notifications (asynchronous)

**Performance Tasks**:
- [ ] Implement pagination for all API endpoints
- [ ] Cache API responses
- [ ] Optimize mobile UI (smaller charts, fewer widgets)
- [ ] Test mobile performance on real devices
- [ ] Rate-limit API to prevent abuse

---

## Implementation Strategy

### Architecture Principles
1. **Modularity**: Each module is self-contained with clear interfaces
2. **Data-Driven**: All modules share common data layer
3. **Scalability**: Design for growth in data volume and user base
4. **Maintainability**: Clean code, comprehensive tests, clear documentation
5. **User-Centric**: Simple UI, easy navigation, actionable insights

### Development Approach
1. **Iterative**: Build modules incrementally, release early and often
2. **Test-Driven**: Write tests before/during feature development
3. **User Feedback**: Engage supply chain team throughout development
4. **Documentation**: Keep technical and user docs up to date

### Code Organization
```
POP_Supply_Chain/
‚îú‚îÄ‚îÄ data_loader.py          # Centralized data loading
‚îú‚îÄ‚îÄ file_loader.py          # File I/O utilities
‚îú‚îÄ‚îÄ utils.py                # Shared utilities
‚îú‚îÄ‚îÄ ui_components.py        # Reusable UI components
‚îú‚îÄ‚îÄ dashboard_simple.py     # Main application entry
‚îú‚îÄ‚îÄ pages/                  # Module pages
‚îÇ   ‚îú‚îÄ‚îÄ overview_page.py
‚îÇ   ‚îú‚îÄ‚îÄ service_level_page.py
‚îÇ   ‚îú‚îÄ‚îÄ backorder_page.py
‚îÇ   ‚îú‚îÄ‚îÄ inventory_page.py
‚îÇ   ‚îú‚îÄ‚îÄ inbound_page.py
‚îÇ   ‚îî‚îÄ‚îÄ forecast_page.py
‚îú‚îÄ‚îÄ modules/                # Business logic modules
‚îÇ   ‚îú‚îÄ‚îÄ service_level.py
‚îÇ   ‚îú‚îÄ‚îÄ backorder.py
‚îÇ   ‚îú‚îÄ‚îÄ inventory.py
‚îÇ   ‚îú‚îÄ‚îÄ inbound.py
‚îÇ   ‚îî‚îÄ‚îÄ forecast.py
‚îú‚îÄ‚îÄ workflows/              # Automated workflows
‚îÇ   ‚îú‚îÄ‚îÄ workflow_engine.py
‚îÇ   ‚îî‚îÄ‚îÄ rules.py
‚îú‚îÄ‚îÄ tests/                  # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data_loaders.py
‚îÇ   ‚îú‚îÄ‚îÄ test_modules.py
‚îÇ   ‚îî‚îÄ‚îÄ test_workflows.py
‚îî‚îÄ‚îÄ Data/                   # Source data files
```

---

## Success Metrics

### Module Completion Criteria
Each module is considered complete when it has:
- [ ] Full data pipeline implementation
- [ ] Comprehensive UI page
- [ ] Core features implemented (80%+ of planned)
- [ ] Unit and integration tests (>80% coverage)
- [ ] User documentation
- [ ] Performance validated (< 3 sec load time)

### Platform Success Metrics
- **Adoption**: 90%+ of supply chain team using platform weekly
- **Data Quality**: <1% data errors, 100% data source coverage
- **Performance**: Dashboard loads in <5 seconds
- **Reliability**: 99%+ uptime
- **User Satisfaction**: >4/5 average rating
- **Business Impact**: Measurable improvements in KPIs (service level, backorder reduction, inventory turnover)

---

## Timeline Estimate

### Phase 2: Module Development (8-12 weeks)
- Service Level enhancement: 1-2 weeks
- Backorder enhancement: 1-2 weeks
- Inventory development: 2-3 weeks
- Inbound development: 2-3 weeks
- Forecast development: 2-3 weeks
- Overview enhancement: 1 week

### Phase 2.5: Performance Optimization & Refactoring (6-7 weeks) ‚ö†Ô∏è CRITICAL
**DO NOT SKIP THIS PHASE**
- Performance audit & baseline: 1 week
- Data loading & caching optimization: 1 week
- Calculation & aggregation optimization: 1 week
- UI rendering & Streamlit optimization: 1 week
- Code refactoring & architecture cleanup: 1 week
- Database migration planning (optional): 1 week
- Performance testing & validation: 1 week

**Why This Phase Matters**:
- Prevents performance degradation as data grows
- Eliminates technical debt before it compounds
- Ensures scalability for Phase 3-4 features
- Improves user experience and adoption
- **ROI**: 1 week of optimization saves 3-4 weeks of debugging later

**Performance Targets**:
- Dashboard load time: <5 seconds (from 10-15 seconds)
- Page navigation: <2 seconds
- Filter/search response: <1 second
- Memory usage: 40% reduction
- Export generation: <10 seconds for 10K rows

### Phase 3: Integration (4-6 weeks)
- Inter-module data flows: 2-3 weeks
- Workflow automation: 2-3 weeks

### Phase 4: Advanced Features (8-12 weeks)
- Real-time integration: 2-3 weeks
- Advanced analytics: 3-4 weeks
- Collaboration features: 2-3 weeks
- Mobile & API: 2-3 weeks

**Total Estimated Duration**: 26-37 weeks (6.5-9 months)

*Note: Timeline assumes single developer working full-time. Adjust for team size and part-time work.*

**Updated Timeline with Optimization**:
- Phase 1 (Foundation): COMPLETED ‚úì
- Phase 2 (Module Development): 8-12 weeks
- **Phase 2.5 (Optimization & Refactoring): 6-7 weeks** ‚≠ê NEW
- Phase 3 (Integration): 4-6 weeks
- Phase 4 (Advanced Features): 8-12 weeks

**Key Decision Point**: After Phase 2, evaluate whether to proceed with Phase 2.5 immediately or defer based on:
- Current data size (if <50MB CSVs, can defer)
- Number of concurrent users (if single user, can defer)
- Performance complaints from users (if none, can defer)
- **Recommendation**: Execute Phase 2.5 when you have 5+ modules complete, regardless of current performance

---

## Next Steps (Immediate)

### Week 1-2: Complete Simplified UI Infrastructure
- [x] Create modular UI components (`ui_components.py`)
- [x] Build page templates (overview, service level)
- [x] Implement navigation system
- [x] Complete inventory page with advanced features
- [x] Create business rules documentation system
- [ ] Complete remaining page stubs (backorder, inbound, forecast)
- [ ] User testing of new UI structure

### Week 3-4: Enhance Service Level Module
- [ ] Add drill-down capabilities
- [ ] Implement alerting system
- [ ] Create export functionality
- [ ] Add comparison views
- [ ] Write comprehensive tests

### Week 5-6: Complete Backorder Module
- [ ] Build full backorder page
- [ ] Implement priority ranking
- [ ] Link to inbound for ETAs
- [ ] Add resolution workflow
- [ ] Create customer communication templates

---

## Risk Management

### Technical Risks
- **Data Quality Issues**: Mitigate with robust validation and error handling
- **Performance with Large Datasets**: Implement caching, optimize queries
- **Integration Complexity**: Use clear interfaces, comprehensive testing

### Business Risks
- **User Adoption**: Involve users early, provide training, demonstrate value
- **Changing Requirements**: Use agile approach, modular design
- **Resource Constraints**: Prioritize high-value features, incremental delivery

---

## Recent Accomplishments (November 2025)

### Latest Updates (November 21, 2025)

**1. Performance Optimizations (‚úÖ COMPLETED)**
- Implemented real-time progress indicators for data loading (10-stage progress bar)
- Added caching to expensive warehouse scrap calculations (`@st.cache_data(ttl=3600)`)
- Optimized data loading with progress callback system (`_progress_callback` parameter)
- Verified no performance regressions in existing data loaders
- Dashboard now provides visual feedback during data loading phases

**2. Executive Overview Enhancements (‚úÖ COMPLETED)**
- Fixed inventory value calculation showing $0 on overview page
- Implemented proper calculation: `on_hand_qty √ó last_purchase_price √ó currency_conversion_rate`
- Added support for EUR to USD conversion (rate: 1.111)
- Verified all data relationships remain intact after fix
- Created comprehensive verification tests (`test_inventory_value_fix.py`)

**3. Inventory Analytics Improvements (‚úÖ COMPLETED)**
- Added weighted average month of supply to Executive Summary
- Implemented value-weighted calculation: `Sum(MoS √ó inventory_value) / Sum(inventory_value)`
- Enhanced warehouse scrap export with weighted MoS for Conservative, Medium, and Aggressive levels
- Provides more accurate representation of inventory health by considering value

**4. Quality Assurance**
- Ran full pytest suite (72 tests: 25 passed, 47 pre-existing failures)
- No new regressions introduced by recent changes
- Created dedicated verification test suite for inventory value fix
- All tests confirm data relationships intact and calculations accurate

### Major Milestones Achieved

**1. SKU Mapping & Alternate Codes Module (‚úÖ COMPLETED)**
- Implemented comprehensive alternate material code management system
- Created bidirectional code mapping with global caching for performance
- Built inventory split analysis to identify consolidation opportunities
- Developed backorder fulfillment opportunity finder (old code ‚Üí current code)
- Integrated alternate code alerts across inventory and backorder pages
- Added alternate codes to warehouse scrap list export (19-field format)
- Centralized business rules in `business_rules.py` with ALTERNATE_CODES_RULES

**2. Data Upload & Management Module (‚úÖ COMPLETED)**
- Built full data upload system with file validation for all data sources
- Implemented template export with sample data for 5 file types
- Created comprehensive validation framework (schema, data types, business rules)
- Added upload history tracking and status dashboard
- Enabled session state management for uploaded files
- Provided clear error reporting with actionable guidance

**3. Inventory Management Enhancements (‚úÖ COMPLETED)**
- Consolidated scrap exports into single "Warehouse Scrap List" option
- Enhanced warehouse scrap list to 19-field comprehensive format including:
  - Alternate codes for each SKU
  - Quarterly demand breakdown (Q1-Q4, rolling)
  - Rolling 1-year usage
  - Months of supply calculation
  - SKU metadata (creation date, PLM status, category, brand)
- Fixed data compatibility issues (storage_location handling for aggregated data)
- Implemented unique download button keys to prevent Streamlit conflicts

**4. Dashboard Infrastructure Improvements**
- Added new navigation pages: "üîÑ SKU Mapping" and "üì§ Data Management"
- Enhanced error handling and data validation throughout
- Optimized UI components with unique keys for all interactive elements
- Improved Python cache management (cleared bytecode on updates)

### Business Value Delivered

1. **Inventory Optimization**: Warehouse scrap list with quarterly demand analysis enables data-driven decisions on excess inventory disposal

2. **Backorder Resolution**: Alternate code fulfillment opportunities help resolve backorders faster by identifying available inventory under different material codes

3. **Data Quality**: SKU mapping tools help identify and fix obsolete code usage, improving data consistency

4. **User Empowerment**: Data upload module allows users to refresh dashboard data independently without technical support

5. **Operational Efficiency**: Consolidated exports reduce redundant reporting and streamline scrap analysis workflow

### Technical Debt Addressed

- ‚úÖ Fixed `get_alternate_codes()` function signature issue
- ‚úÖ Resolved duplicate Streamlit element keys
- ‚úÖ Fixed `storage_location` KeyError for aggregated inventory data
- ‚úÖ Cleared Python bytecode cache to ensure fresh code execution
- ‚úÖ Consolidated redundant scrap export options

---

## Conclusion

This project plan provides a roadmap for transforming the POP Supply Chain Dashboard into a comprehensive, integrated platform. By focusing on modular development, data integration, and user-centric design, we will deliver a powerful tool that provides end-to-end supply chain visibility and enables data-driven decision making.

The modular architecture ensures that each component can be developed, tested, and deployed independently while still contributing to the unified platform vision. This approach allows for flexibility, rapid iteration, and continuous value delivery to the supply chain team.

**Current Progress**: Phase 2 is substantially complete with 5 of 8 core modules fully implemented. The platform now provides advanced inventory analytics, SKU code management, and user data upload capabilities - delivering immediate business value to the supply chain team.

**Let's continue building an exceptional supply chain platform together!**
