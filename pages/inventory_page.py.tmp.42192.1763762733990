"""
Inventory Page - Enhanced
Comprehensive inventory analysis with:
- Slow-moving, obsolescence, and scrap opportunities
- ABC Analysis
- Stock-out risk alerts
- Currency conversion (USD/EUR)
- Adjustable thresholds
- Future-ready for monthly snapshots
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
import numpy as np
import sys
import os
from io import BytesIO
from datetime import datetime
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from ui_components import (
    render_page_header, render_kpi_row, render_chart,
    render_data_table, render_filter_section, render_info_box
)
from business_rules import (
    convert_currency, get_movement_classification, get_stock_out_risk_level,
    get_scrap_threshold, INVENTORY_RULES, CURRENCY_RULES
)

# ===== SETTINGS AND CONFIGURATION =====

def render_inventory_settings_sidebar():
    """Render adjustable settings in sidebar - organized for optimal UX"""

    # === 1. SEARCH & FILTERS (Most frequently used) ===
    st.sidebar.header("üîç Search & Filters")

    sku_search = st.sidebar.text_input(
        "Search SKU",
        value="",
        key="sku_search",
        placeholder="Enter SKU code...",
        help="Search for specific SKU (partial match supported)"
    )

    currency = st.sidebar.selectbox(
        "Display Currency",
        options=CURRENCY_RULES["supported_currencies"],
        index=0,
        key="inv_currency",
        help="Select currency for all value displays"
    )

    st.sidebar.divider()

    # === 2. ALERT THRESHOLDS (Important operational settings) ===
    st.sidebar.header("‚ö†Ô∏è Alert Thresholds")

    stockout_threshold = st.sidebar.slider(
        "Stock-Out Alert (days)",
        min_value=1,
        max_value=30,
        value=INVENTORY_RULES["stock_out_risk"]["critical_dio"],
        step=1,
        key="stockout_threshold",
        help="Alert when DIO falls below this threshold"
    )

    default_threshold = INVENTORY_RULES["scrap_criteria"]["default_dio_threshold"]
    min_threshold = INVENTORY_RULES["scrap_criteria"]["min_dio_threshold"]
    max_threshold = INVENTORY_RULES["scrap_criteria"]["max_dio_threshold"]

    scrap_threshold = st.sidebar.slider(
        "Scrap Threshold (days)",
        min_value=min_threshold,
        max_value=max_threshold,
        value=default_threshold,
        step=30,
        key="scrap_threshold",
        help=f"Flag items for scrap when DIO exceeds this (Default: {default_threshold//365} years)"
    )

    st.sidebar.divider()

    # === 3. ANALYSIS CONFIGURATION (Advanced settings - collapsed by default) ===
    with st.sidebar.expander("üìä Analysis Configuration", expanded=False):
        st.caption("**ABC Classification Method**")
        abc_method = st.radio(
            "Method",
            options=["Value-Based (80/15/5)", "Count-Based (20/30/50)"],
            index=0,
            key="abc_method",
            help="Value: A=80% of value | Count: A=20% of SKUs",
            label_visibility="collapsed"
        )
        use_count_based = "Count-Based" in abc_method

        st.divider()

        st.caption("**DIO Bucket Boundaries**")
        use_custom_buckets = st.checkbox(
            "Customize Buckets",
            value=False,
            key="use_custom_buckets",
            help="Customize DIO bucket boundaries for charts"
        )

        if use_custom_buckets:
            st.caption("Set bucket boundaries (in days):")
            bucket_30 = st.number_input("Bucket 1", min_value=1, max_value=90, value=30, step=5, key="bucket_30")
            bucket_60 = st.number_input("Bucket 2", min_value=bucket_30+1, max_value=180, value=60, step=5, key="bucket_60")
            bucket_90 = st.number_input("Bucket 3", min_value=bucket_60+1, max_value=270, value=90, step=10, key="bucket_90")
            bucket_180 = st.number_input("Bucket 4", min_value=bucket_90+1, max_value=365, value=180, step=10, key="bucket_180")
            bucket_365 = st.number_input("Bucket 5", min_value=bucket_180+1, max_value=730, value=365, step=30, key="bucket_365")

            dio_buckets = [0, 0.1, bucket_30, bucket_60, bucket_90, bucket_180, bucket_365, float('inf')]
        else:
            dio_buckets = INVENTORY_RULES["variable_buckets"]["default_boundaries"]
            dio_buckets = [0, 0.1] + dio_buckets + [float('inf')]

    st.sidebar.divider()

    # === 4. EXPORT (Action-oriented - at bottom) ===
    st.sidebar.header("üì• Export Data")

    export_section = st.sidebar.selectbox(
        "Select dataset:",
        options=[
            "All Inventory Data",
            "Scrap Candidates",
            "Stock-Out Risks",
            "Slow-Moving Items (Top 50)",
            "ABC Class A Items",
            "ABC Class B Items",
            "ABC Class C Items",
            "Dead Stock Items",
            "Warehouse Scrap List (All SKUs)"
        ],
        key="export_section",
        help="Choose which data to export to Excel"
    )

    # Scrap threshold slider (only shown for Warehouse Scrap List)
    scrap_days_threshold = 730  # Default to 2 years
    if export_section == "Warehouse Scrap List (All SKUs)":
        scrap_days_threshold = st.sidebar.slider(
            "Scrap Threshold (Days of Supply)",
            min_value=365,
            max_value=1095,
            value=730,
            step=30,
            help="SKUs with inventory exceeding this many days of supply will be marked for potential scrap. Default: 730 days (2 years)"
        )

    st.sidebar.divider()

    return {
        "currency": currency,
        "scrap_threshold": scrap_threshold,
        "stockout_threshold": stockout_threshold,
        "sku_search": sku_search,
        "export_section": export_section,
        "dio_buckets": dio_buckets,
        "use_custom_buckets": use_custom_buckets,
        "use_count_based_abc": use_count_based,
        "scrap_days_threshold": scrap_days_threshold
    }

# ===== EXPORT FUNCTIONS =====

def create_excel_export(data, section_name, currency="USD"):
    """
    Create Excel file with formatted data

    Args:
        data: DataFrame to export
        section_name: Name of the section being exported
        currency: Currency for value columns

    Returns:
        BytesIO object containing Excel file
    """
    output = BytesIO()

    # Create a copy to avoid modifying original
    export_df = data.copy()

    # Select relevant columns and format
    value_col = f'stock_value_{currency.lower()}'

    columns_to_export = []
    if 'sku' in export_df.columns:
        columns_to_export.append('sku')
    if 'category' in export_df.columns:
        columns_to_export.append('category')
    if 'on_hand_qty' in export_df.columns:
        columns_to_export.append('on_hand_qty')
    if 'in_transit_qty' in export_df.columns:
        columns_to_export.append('in_transit_qty')
    if 'daily_demand' in export_df.columns:
        columns_to_export.append('daily_demand')
    if 'dio' in export_df.columns:
        columns_to_export.append('dio')
    if value_col in export_df.columns:
        columns_to_export.append(value_col)
    if 'movement_class' in export_df.columns:
        columns_to_export.append('movement_class')
    if 'stock_out_risk' in export_df.columns:
        columns_to_export.append('stock_out_risk')
    if 'abc_class' in export_df.columns:
        columns_to_export.append('abc_class')
    if 'last_purchase_price' in export_df.columns:
        columns_to_export.append('last_purchase_price')

    export_df = export_df[columns_to_export]

    # Rename columns for readability
    column_names = {
        'sku': 'SKU',
        'category': 'Category',
        'on_hand_qty': 'On Hand Qty',
        'in_transit_qty': 'In Transit Qty',
        'daily_demand': 'Daily Demand',
        'dio': 'DIO (days)',
        value_col: f'Stock Value ({currency})',
        'movement_class': 'Movement Class',
        'stock_out_risk': 'Stock-Out Risk',
        'abc_class': 'ABC Class',
        'last_purchase_price': 'Last Purchase Price'
    }
    export_df = export_df.rename(columns=column_names)

    # Write to Excel with formatting
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        export_df.to_excel(writer, sheet_name=section_name[:31], index=False)  # Excel sheet name limit is 31 chars

        # Get workbook and worksheet objects
        workbook = writer.book
        worksheet = writer.sheets[section_name[:31]]

        # Add formats
        header_format = workbook.add_format({
            'bold': True,
            'bg_color': '#4472C4',
            'font_color': 'white',
            'border': 1
        })

        # Format header row
        for col_num, value in enumerate(export_df.columns.values):
            worksheet.write(0, col_num, value, header_format)

        # Auto-fit columns
        for i, col in enumerate(export_df.columns):
            max_len = max(
                export_df[col].astype(str).apply(len).max(),
                len(col)
            ) + 2
            worksheet.set_column(i, i, min(max_len, 50))

    output.seek(0)
    return output

def prepare_warehouse_scrap_list(inventory_data, scrap_days_threshold, currency):
    """
    Prepare comprehensive warehouse scrap list with all required fields

    Args:
        inventory_data: Full inventory DataFrame with quarterly demand data
        scrap_days_threshold: Days of supply threshold (default 730 = 2 years)
        currency: Currency for value calculations

    Returns:
        DataFrame with 19 required fields for warehouse scrap analysis
    """
    from business_rules import load_alternate_codes_mapping, get_alternate_codes

    # Filter for SKUs with on-hand inventory only
    df = inventory_data[inventory_data['on_hand_qty'] > 0].copy()

    if df.empty:
        return pd.DataFrame()

    # Load alternate codes
    alt_codes_mapping = load_alternate_codes_mapping()

    # Calculate scrap quantities
    df['scrap_qty'] = df.apply(
        lambda row: max(0, row['on_hand_qty'] - (row['daily_demand'] * scrap_days_threshold))
        if row['daily_demand'] > 0 else row['on_hand_qty'],
        axis=1
    )

    # Calculate scrap value in USD
    df['scrap_value_usd'] = df.apply(
        lambda row: row['scrap_qty'] * convert_currency(
            row['last_purchase_price'],
            row.get('currency', 'USD'),
            'USD'
        ),
        axis=1
    )

    # Calculate months of supply
    df['months_of_supply'] = df['dio'] / 30

    # Get alternate codes for each SKU
    df['alternate_codes'] = df['sku'].apply(
        lambda sku: ', '.join(get_alternate_codes(sku, alt_codes_mapping))
        if get_alternate_codes(sku, alt_codes_mapping) else ''
    )

    # Build the 19-field export
    scrap_list = pd.DataFrame({
        'Material': df['sku'],
        'Alternate Codes': df['alternate_codes'],
        'Storage Location': df['storage_location'],
        'Description': df.get('product_name', ''),
        'SKU Creation Date': df.get('activation_date', ''),
        'Flag Status (PLM Current Status)': df.get('plm_status', ''),
        'Last Inbound Date': df.get('last_inbound_date', ''),  # Will be '' if not available
        'PLM Expiration Date': df.get('plm_expiration_date', ''),
        'Brand': df.get('brand', ''),  # Will be '' if not available
        'Category': df.get('category', ''),
        'STD Price': df['last_purchase_price'],
        'Total STD Price': df['on_hand_qty'] * df['last_purchase_price'],
        'Free Qt': df['on_hand_qty'],
        'Q1 Demand': df.get('q1_demand', 0),
        'Q2 Demand': df.get('q2_demand', 0),
        'Q3 Demand': df.get('q3_demand', 0),
        'Q4 Demand': df.get('q4_demand', 0),
        'Rolling 1 Yr Usage': df.get('rolling_1yr_usage', 0),
        '# of Qtrs with History': df.get('qtrs_with_history', 0),
        'Months of Supply': df['months_of_supply'],
        'Qty over 2 Yrs Supply': df['scrap_qty'],
        'USD value over 2 Yrs Supply': df['scrap_value_usd']
    })

    # Sort by scrap value descending (highest value scrap opportunities first)
    scrap_list = scrap_list.sort_values('USD value over 2 Yrs Supply', ascending=False)

    return scrap_list

def prepare_export_data(inventory_data, section, currency, scrap_threshold, scrap_days_threshold=730):
    """
    Prepare data for export based on selected section

    Args:
        inventory_data: Full inventory DataFrame
        section: Selected section name
        currency: Currency for value columns
        scrap_threshold: DIO threshold for scrap candidates
        scrap_days_threshold: Days of supply threshold for warehouse scrap list (default 730 = 2 years)

    Returns:
        Filtered DataFrame
    """
    value_col = f'stock_value_{currency.lower()}'

    if section == "All Inventory Data":
        return inventory_data

    elif section == "Scrap Candidates":
        return inventory_data[inventory_data['dio'] >= scrap_threshold].sort_values(value_col, ascending=False)

    elif section == "Stock-Out Risks":
        return inventory_data[inventory_data['stock_out_risk'] == 'Critical'].sort_values('dio')

    elif section == "Slow-Moving Items (Top 50)":
        slow_movers = inventory_data[
            inventory_data['movement_class'].isin(['Slow Moving', 'Very Slow Moving', 'Obsolete Risk', 'Dead Stock'])
        ]
        return slow_movers.sort_values(value_col, ascending=False).head(50)

    elif section == "ABC Class A Items":
        return inventory_data[inventory_data['abc_class'] == 'A'].sort_values(value_col, ascending=False)

    elif section == "ABC Class B Items":
        return inventory_data[inventory_data['abc_class'] == 'B'].sort_values(value_col, ascending=False)

    elif section == "ABC Class C Items":
        return inventory_data[inventory_data['abc_class'] == 'C'].sort_values(value_col, ascending=False)

    elif section == "Dead Stock Items":
        return inventory_data[inventory_data['movement_class'] == 'Dead Stock'].sort_values(value_col, ascending=False)

    elif section == "Warehouse Scrap List (All SKUs)":
        return prepare_warehouse_scrap_list(inventory_data, scrap_days_threshold, currency)

    return inventory_data

# ===== FILTERING =====

def get_inventory_filters(inventory_data):
    """Define filters for inventory page"""
    if inventory_data.empty:
        return []

    filters = []

    # Category filter
    if 'category' in inventory_data.columns:
        categories = ['All'] + sorted(inventory_data['category'].dropna().unique().tolist())
        filters.append({
            "type": "selectbox",
            "label": "Category",
            "options": categories,
            "key": "inv_category_filter"
        })

    # Movement classification filter
    if 'movement_class' in inventory_data.columns:
        movement_classes = ['All'] + sorted(inventory_data['movement_class'].dropna().unique().tolist())
        filters.append({
            "type": "selectbox",
            "label": "Movement Classification",
            "options": movement_classes,
            "key": "inv_movement_filter"
        })

    # Stock-out risk filter
    if 'stock_out_risk' in inventory_data.columns:
        risk_levels = ['All'] + sorted(inventory_data['stock_out_risk'].dropna().unique().tolist())
        filters.append({
            "type": "selectbox",
            "label": "Stock-Out Risk",
            "options": risk_levels,
            "key": "inv_risk_filter"
        })

    # ABC Classification filter
    if 'abc_class' in inventory_data.columns:
        abc_classes = ['All'] + sorted(inventory_data['abc_class'].dropna().unique().tolist())
        filters.append({
            "type": "selectbox",
            "label": "ABC Classification",
            "options": abc_classes,
            "key": "inv_abc_filter"
        })

    # DIO range filter
    filters.append({
        "type": "selectbox",
        "label": "DIO Range",
        "options": ['All', '0-30 days', '31-60 days', '61-90 days', '91-180 days', '180-365 days', '365+ days', 'No Movement'],
        "key": "inv_dio_filter"
    })

    return filters

def apply_inventory_filters(inventory_data, filter_values, settings):
    """Apply selected filters to inventory data"""
    filtered = inventory_data

    if 'inv_category_filter' in filter_values and filter_values['inv_category_filter'] != 'All':
        filtered = filtered[filtered['category'] == filter_values['inv_category_filter']]

    if 'inv_movement_filter' in filter_values and filter_values['inv_movement_filter'] != 'All':
        filtered = filtered[filtered['movement_class'] == filter_values['inv_movement_filter']]

    if 'inv_risk_filter' in filter_values and filter_values['inv_risk_filter'] != 'All':
        filtered = filtered[filtered['stock_out_risk'] == filter_values['inv_risk_filter']]

    if 'inv_abc_filter' in filter_values and filter_values['inv_abc_filter'] != 'All':
        filtered = filtered[filtered['abc_class'] == filter_values['inv_abc_filter']]

    if 'inv_dio_filter' in filter_values and filter_values['inv_dio_filter'] != 'All':
        dio_range = filter_values['inv_dio_filter']
        if dio_range == '0-30 days':
            filtered = filtered[(filtered['dio'] > 0) & (filtered['dio'] <= 30)]
        elif dio_range == '31-60 days':
            filtered = filtered[(filtered['dio'] > 30) & (filtered['dio'] <= 60)]
        elif dio_range == '61-90 days':
            filtered = filtered[(filtered['dio'] > 60) & (filtered['dio'] <= 90)]
        elif dio_range == '91-180 days':
            filtered = filtered[(filtered['dio'] > 90) & (filtered['dio'] <= 180)]
        elif dio_range == '180-365 days':
            filtered = filtered[(filtered['dio'] > 180) & (filtered['dio'] <= 365)]
        elif dio_range == '365+ days':
            filtered = filtered[filtered['dio'] > 365]
        elif dio_range == 'No Movement':
            filtered = filtered[filtered['dio'] == 0]

    # Apply SKU search
    if settings['sku_search']:
        filtered = filtered[filtered['sku'].str.contains(settings['sku_search'], case=False, na=False)]

    return filtered

# ===== ABC ANALYSIS =====

def calculate_abc_classification(inventory_data, use_count_based=False):
    """
    Calculate ABC classification based on value or count

    Args:
        inventory_data: DataFrame with inventory data
        use_count_based: If True, use count-based (top 20% of SKUs = A),
                        if False, use value-based (top 80% of value = A)
    """
    if inventory_data.empty or 'stock_value_usd' not in inventory_data.columns:
        return inventory_data

    # Sort by value descending
    sorted_data = inventory_data.sort_values('stock_value_usd', ascending=False).copy()

    if use_count_based:
        # Count-based: Top X% of SKUs by value
        total_skus = len(sorted_data)
        a_count_pct = INVENTORY_RULES["abc_analysis"]["a_class_count_pct"]
        b_count_pct = INVENTORY_RULES["abc_analysis"]["b_class_count_pct"]

        a_cutoff = int(total_skus * a_count_pct / 100)
        b_cutoff = int(total_skus * (a_count_pct + b_count_pct) / 100)

        sorted_data['abc_class'] = 'C'  # Default
        sorted_data.iloc[:a_cutoff, sorted_data.columns.get_loc('abc_class')] = 'A'
        sorted_data.iloc[a_cutoff:b_cutoff, sorted_data.columns.get_loc('abc_class')] = 'B'

    else:
        # Value-based: Top X% of cumulative value
        sorted_data['cumulative_value'] = sorted_data['stock_value_usd'].cumsum()
        total_value = sorted_data['stock_value_usd'].sum()

        if total_value == 0:
            sorted_data['abc_class'] = 'C'
            return sorted_data

        sorted_data['cumulative_pct'] = (sorted_data['cumulative_value'] / total_value) * 100

        # Classify based on cumulative percentage
        a_threshold = INVENTORY_RULES["abc_analysis"]["a_class_threshold"]
        b_threshold = INVENTORY_RULES["abc_analysis"]["b_class_threshold"]

        sorted_data['abc_class'] = 'C'  # Default
        sorted_data.loc[sorted_data['cumulative_pct'] <= a_threshold, 'abc_class'] = 'A'
        sorted_data.loc[(sorted_data['cumulative_pct'] > a_threshold) &
                        (sorted_data['cumulative_pct'] <= b_threshold), 'abc_class'] = 'B'

    return sorted_data

# ===== METRICS CALCULATION =====

def calculate_inventory_metrics(inventory_data, currency="USD"):
    """Calculate key inventory metrics"""
    if inventory_data.empty:
        return {}

    # Use currency-specific value column
    value_col = f'stock_value_{currency.lower()}'

    total_units = inventory_data['on_hand_qty'].sum()
    total_skus = len(inventory_data)
    total_value = inventory_data[value_col].sum()

    # Calculate average DIO
    dio_data = inventory_data[inventory_data['dio'] > 0]
    avg_dio = dio_data['dio'].mean() if not dio_data.empty else 0

    # Count slow-moving/obsolete items
    slow_moving_count = len(inventory_data[inventory_data['movement_class'].isin(
        ['Slow Moving', 'Very Slow Moving', 'Obsolete Risk', 'Dead Stock'])])

    # Count stock-out risks
    critical_risk_count = len(inventory_data[inventory_data['stock_out_risk'] == 'Critical'])

    currency_symbol = "$" if currency == "USD" else "‚Ç¨"

    return {
        f"Total Value ({currency})": {
            "value": f"{currency_symbol}{total_value:,.0f}",
            "help": f"**Business Logic:** Sum of (On-Hand Qty √ó Last Purchase Price) for all SKUs, converted to {currency}. Formula: Œ£(stock_qty √ó unit_price)"
        },
        "Total Units": {
            "value": f"{int(total_units):,}",
            "help": "**Business Logic:** Sum of all on-hand quantities across all SKUs. Represents total physical units in inventory. Formula: Œ£(on_hand_qty)"
        },
        "Total SKUs": {
            "value": f"{total_skus:,}",
            "help": "**Business Logic:** Count of unique material numbers (SKUs) with inventory. Each SKU represents a distinct product in the catalog. Formula: COUNT(DISTINCT sku)"
        },
        "Avg DIO": {
            "value": f"{avg_dio:.0f} days",
            "help": f"**Business Logic:** Average Days Inventory Outstanding across SKUs with movement. DIO = On-Hand Qty √∑ Daily Demand. Daily Demand = Last 12 months deliveries √∑ days since market intro (capped at 365). Excludes SKUs with zero demand. Current average: {avg_dio:.1f} days. Formula: AVG(DIO WHERE DIO > 0)"
        },
        "Slow/Obsolete SKUs": {
            "value": f"{slow_moving_count:,}",
            "help": "**Business Logic:** Count of SKUs classified as Slow Moving (DIO 60-90 days), Very Slow (90-180 days), Obsolete Risk (>180 days), or Dead Stock (no movement in 12 months). Based on movement velocity thresholds in business rules. Formula: COUNT(WHERE movement_class IN ['Slow Moving', 'Very Slow Moving', 'Obsolete Risk', 'Dead Stock'])"
        },
        "Stock-Out Risks": {
            "value": f"{critical_risk_count:,}",
            "help": "**Business Logic:** Count of SKUs with Critical stock-out risk (DIO < 7 days). These items may run out within a week based on current demand. Excludes items with zero demand. Formula: COUNT(WHERE DIO < 7 AND DIO > 0)",
            "delta": f"-{critical_risk_count}" if critical_risk_count > 0 else None,
            "delta_color": "inverse"
        }
    }

# ===== VISUALIZATIONS =====

def render_dio_distribution_chart(inventory_data, currency="USD", dio_buckets=None):
    """Render DIO distribution chart with configurable buckets"""
    if inventory_data.empty:
        return None

    value_col = f'stock_value_{currency.lower()}'

    # Use provided buckets or default
    if dio_buckets is None:
        dio_buckets = [0, 0.1, 30, 60, 90, 180, 365, float('inf')]

    # Generate labels dynamically based on bucket boundaries
    labels = []
    for i in range(len(dio_buckets) - 1):
        lower = dio_buckets[i]
        upper = dio_buckets[i + 1]

        if lower == 0 and upper <= 1:
            labels.append('No Movement')
        elif upper == float('inf'):
            labels.append(f'{int(lower)}+ days')
        else:
            labels.append(f'{int(lower)}-{int(upper)} days')

    # Create DIO buckets
    inventory_data['dio_bucket'] = pd.cut(
        inventory_data['dio'],
        bins=dio_buckets,
        labels=labels,
        include_lowest=True
    )

    dio_summary = inventory_data.groupby('dio_bucket', observed=True).agg({
        'on_hand_qty': 'sum',
        value_col: 'sum',
        'sku': 'count'
    }).reset_index()
    dio_summary.columns = ['dio_bucket', 'units', 'value', 'sku_count']

    # Create subplot with two y-axes
    fig = make_subplots(specs=[[{"secondary_y": True}]])

    fig.add_trace(
        go.Bar(
            x=dio_summary['dio_bucket'],
            y=dio_summary['value'],
            name=f'Inventory Value ({currency})',
            marker_color=['#FF6B6B', '#06D6A0', '#4ECDC4', '#45B7D1', '#FFA07A', '#FF8C42', '#C73E1D']
        ),
        secondary_y=False
    )

    fig.add_trace(
        go.Scatter(
            x=dio_summary['dio_bucket'],
            y=dio_summary['sku_count'],
            name='SKU Count',
            mode='lines+markers',
            line=dict(color='#2C3E50', width=3),
            marker=dict(size=10)
        ),
        secondary_y=True
    )

    currency_symbol = '$' if currency == "USD" else '‚Ç¨'
    fig.update_xaxes(title_text="DIO Range")
    fig.update_yaxes(title_text=f"Inventory Value ({currency_symbol})", secondary_y=False)
    fig.update_yaxes(title_text="Number of SKUs", secondary_y=True)

    fig.update_layout(
        title="Inventory Distribution by DIO",
        hovermode='x unified',
        height=400
    )

    return fig

def render_movement_classification_chart(inventory_data, currency="USD"):
    """Render movement classification pie chart"""
    if inventory_data.empty or 'movement_class' not in inventory_data.columns:
        return None

    value_col = f'stock_value_{currency.lower()}'

    movement_summary = inventory_data.groupby('movement_class').agg({
        value_col: 'sum',
        'sku': 'count'
    }).reset_index()
    movement_summary.columns = ['movement_class', 'value', 'count']

    # Sort by value
    movement_summary = movement_summary.sort_values('value', ascending=False)

    # Define colors for each movement class
    color_map = {
        'Fast Moving': '#06D6A0',
        'Normal Moving': '#4ECDC4',
        'Slow Moving': '#FFD166',
        'Very Slow Moving': '#EF8354',
        'Obsolete Risk': '#F4442E',
        'Dead Stock': '#A71E2C'
    }
    colors = [color_map.get(cat, '#95A5A6') for cat in movement_summary['movement_class']]

    currency_symbol = '$' if currency == "USD" else '‚Ç¨'
    fig = go.Figure(data=[go.Pie(
        labels=movement_summary['movement_class'],
        values=movement_summary['value'],
        marker=dict(colors=colors),
        textposition='inside',
        textinfo='percent+label',
        hovertemplate=f'<b>%{{label}}</b><br>Value: {currency_symbol}%{{value:,.0f}}<br>Percentage: %{{percent}}<extra></extra>'
    )])

    fig.update_layout(
        title="Inventory Value by Movement Classification",
        height=400
    )

    return fig

def render_abc_analysis_chart(inventory_data, currency="USD"):
    """Render ABC analysis Pareto chart"""
    if inventory_data.empty or 'abc_class' not in inventory_data.columns:
        return None

    value_col = f'stock_value_{currency.lower()}'

    abc_summary = inventory_data.groupby('abc_class').agg({
        value_col: 'sum',
        'sku': 'count'
    }).reset_index()
    abc_summary.columns = ['abc_class', 'value', 'sku_count']

    # Ensure proper order
    abc_order = ['A', 'B', 'C']
    abc_summary['abc_class'] = pd.Categorical(abc_summary['abc_class'], categories=abc_order, ordered=True)
    abc_summary = abc_summary.sort_values('abc_class')

    # Calculate percentages
    total_value = abc_summary['value'].sum()
    abc_summary['value_pct'] = (abc_summary['value'] / total_value * 100) if total_value > 0 else 0

    fig = make_subplots(specs=[[{"secondary_y": True}]])

    fig.add_trace(
        go.Bar(
            x=abc_summary['abc_class'],
            y=abc_summary['value'],
            name=f'Value ({currency})',
            marker_color=['#06D6A0', '#FFA07A', '#FF6B6B'],
            text=abc_summary['value_pct'].apply(lambda x: f'{x:.1f}%'),
            textposition='outside'
        ),
        secondary_y=False
    )

    fig.add_trace(
        go.Scatter(
            x=abc_summary['abc_class'],
            y=abc_summary['sku_count'],
            name='SKU Count',
            mode='lines+markers',
            line=dict(color='#2C3E50', width=3),
            marker=dict(size=12)
        ),
        secondary_y=True
    )

    currency_symbol = '$' if currency == "USD" else '‚Ç¨'
    fig.update_xaxes(title_text="ABC Classification")
    fig.update_yaxes(title_text=f"Inventory Value ({currency_symbol})", secondary_y=False)
    fig.update_yaxes(title_text="Number of SKUs", secondary_y=True)

    fig.update_layout(
        title="ABC Analysis (Pareto)",
        hovermode='x unified',
        height=400
    )

    return fig

def render_category_heatmap(inventory_data, currency="USD"):
    """Render category benchmarking heat map"""
    if inventory_data.empty or 'category' not in inventory_data.columns:
        return None

    value_col = f'stock_value_{currency.lower()}'

    # Calculate metrics by category
    category_summary = inventory_data.groupby('category').agg({
        'dio': 'mean',
        value_col: 'sum',
        'sku': 'count',
        'on_hand_qty': 'sum'
    }).reset_index()

    category_summary.columns = ['category', 'avg_dio', 'total_value', 'sku_count', 'total_units']

    # Add movement class distribution
    movement_dist = inventory_data.groupby(['category', 'movement_class']).size().unstack(fill_value=0)
    if 'Slow Moving' in movement_dist.columns:
        category_summary = category_summary.merge(
            movement_dist[['Slow Moving', 'Very Slow Moving', 'Obsolete Risk', 'Dead Stock']].sum(axis=1).reset_index(name='slow_count'),
            left_on='category',
            right_on='category',
            how='left'
        )
    else:
        category_summary['slow_count'] = 0

    category_summary['slow_pct'] = (category_summary['slow_count'] / category_summary['sku_count'] * 100).round(1)

    # Sort by total value
    category_summary = category_summary.sort_values('total_value', ascending=False).head(20)

    # Create heatmap
    fig = go.Figure(data=go.Heatmap(
        z=[category_summary['avg_dio'].values],
        x=category_summary['category'].values,
        y=['Avg DIO (days)'],
        colorscale='RdYlGn_r',
        text=category_summary['avg_dio'].apply(lambda x: f'{x:.0f}').values,
        texttemplate='%{text}',
        textfont={"size": 10},
        hovertemplate='Category: %{x}<br>Avg DIO: %{z:.0f} days<extra></extra>',
        colorbar=dict(title="DIO (days)")
    ))

    fig.update_layout(
        title="Category Benchmarking - Average DIO Heat Map",
        height=200,
        xaxis_title="Category",
        yaxis_title=""
    )

    return fig

# ===== SCRAP OPPORTUNITY ANALYSIS =====

def render_scrap_opportunity_analysis(inventory_data, currency="USD", scrap_threshold=730):
    """Render scrap opportunity analysis section"""
    if inventory_data.empty:
        return

    st.subheader("üí° Scrap & Obsolescence Opportunities")

    value_col = f'stock_value_{currency.lower()}'
    currency_symbol = '$' if currency == "USD" else '‚Ç¨'

    # Define scrap candidates based on adjustable threshold
    scrap_candidates = inventory_data[
        ((inventory_data['dio'] > scrap_threshold) | (inventory_data['dio'] == 0)) &
        (inventory_data['on_hand_qty'] > 0)
    ].copy()

    if scrap_candidates.empty:
        render_info_box(f"No items identified for scrap consideration based on current criteria (DIO > {scrap_threshold} days or no movement)", type="success")
        return

    scrap_value = scrap_candidates[value_col].sum()
    scrap_units = scrap_candidates['on_hand_qty'].sum()
    scrap_skus = len(scrap_candidates)

    # Display scrap opportunity metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Potential Scrap Value", f"{currency_symbol}{scrap_value:,.0f}",
                  help=f"Total value of items with no movement or DIO > {scrap_threshold} days")
    with col2:
        st.metric("Units to Review", f"{int(scrap_units):,}", help="Total units flagged for scrap review")
    with col3:
        st.metric("SKUs to Review", f"{scrap_skus:,}", help="Number of SKUs flagged for scrap consideration")

    # Category breakdown
    st.markdown("#### Scrap Candidates by Category")
    scrap_by_category = scrap_candidates.groupby('category').agg({
        value_col: 'sum',
        'on_hand_qty': 'sum',
        'sku': 'count'
    }).reset_index().sort_values(value_col, ascending=False)

    scrap_by_category.columns = ['Category', 'Total Value', 'Total Units', 'SKU Count']
    scrap_by_category['Total Value'] = scrap_by_category['Total Value'].apply(lambda x: f"{currency_symbol}{x:,.0f}")
    scrap_by_category['Total Units'] = scrap_by_category['Total Units'].apply(lambda x: f"{int(x):,}")

    st.dataframe(scrap_by_category, hide_index=True, width='stretch')

    # Detailed scrap list
    with st.expander("üìã Detailed Scrap Candidate List", expanded=False):
        scrap_detail = scrap_candidates[['sku', 'category', 'on_hand_qty', 'dio', 'daily_demand', 'last_purchase_price', value_col]].copy()
        scrap_detail = scrap_detail.sort_values(value_col, ascending=False)

        # Format columns
        scrap_detail['dio'] = scrap_detail['dio'].round(0).astype(int)
        scrap_detail['daily_demand'] = scrap_detail['daily_demand'].round(2)
        scrap_detail['last_purchase_price'] = scrap_detail['last_purchase_price'].round(2)
        scrap_detail[value_col] = scrap_detail[value_col].round(2)

        scrap_detail.columns = ['SKU', 'Category', 'On Hand Qty', 'DIO (days)', 'Daily Demand', 'Unit Price', f'Stock Value ({currency})']

        render_data_table(
            scrap_detail,
            max_rows=100
        )

# ===== STOCK-OUT RISK ANALYSIS =====

def render_stockout_risk_analysis(inventory_data, currency="USD"):
    """Render stock-out risk analysis section"""
    if inventory_data.empty:
        return

    st.subheader("‚ö†Ô∏è Stock-Out Risk Alerts")

    value_col = f'stock_value_{currency.lower()}'

    # Filter for critical and warning risks
    critical_items = inventory_data[inventory_data['stock_out_risk'] == 'Critical'].copy()
    warning_items = inventory_data[inventory_data['stock_out_risk'] == 'Warning'].copy()

    col1, col2 = st.columns(2)

    with col1:
        st.metric("Critical Risk Items", f"{len(critical_items):,}",
                  help="Items with critically low inventory (< 7 days DIO)")

    with col2:
        st.metric("Warning Risk Items", f"{len(warning_items):,}",
                  help="Items with low inventory warning (7-14 days DIO)")

    if not critical_items.empty:
        with st.expander("üî¥ Critical Risk Items", expanded=True):
            critical_detail = critical_items[['sku', 'category', 'on_hand_qty', 'dio', 'daily_demand', value_col]].copy()
            critical_detail = critical_detail.sort_values('dio')

            critical_detail['dio'] = critical_detail['dio'].round(1)
            critical_detail['daily_demand'] = critical_detail['daily_demand'].round(2)
            critical_detail[value_col] = critical_detail[value_col].round(2)

            critical_detail.columns = ['SKU', 'Category', 'On Hand Qty', 'DIO (days)', 'Daily Demand', f'Stock Value ({currency})']

            st.dataframe(critical_detail.head(20), hide_index=True, width='stretch')

# ===== MAIN RENDER FUNCTION =====

def render_inventory_page(inventory_data):
    """Main inventory page render function"""

    # Page header
    render_page_header(
        "Inventory Management",
        icon="üì¶",
        subtitle="Inventory levels, turnover analysis, slow-moving/obsolescence tracking, and ABC analysis"
    )

    if inventory_data.empty:
        st.warning("No inventory data available")
        return

    # Render settings sidebar
    settings = render_inventory_settings_sidebar()
    currency = settings['currency']
    scrap_threshold = settings['scrap_threshold']

    # Add calculated columns - currency conversion
    # IMPORTANT: Convert from actual purchase currency to target currency
    # Handle cases where currency column might be missing or NaN
    if 'currency' not in inventory_data.columns:
        inventory_data['currency'] = 'USD'
    else:
        inventory_data['currency'] = inventory_data['currency'].fillna('USD')

    inventory_data['stock_value_usd'] = inventory_data.apply(
        lambda row: row['on_hand_qty'] * convert_currency(
            row['last_purchase_price'],
            row['currency'],  # Source currency from data
            'USD'  # Target currency
        ),
        axis=1
    )
    inventory_data['stock_value_eur'] = inventory_data.apply(
        lambda row: row['on_hand_qty'] * convert_currency(
            row['last_purchase_price'],
            row['currency'],  # Source currency from data
            'EUR'  # Target currency
        ),
        axis=1
    )

    # Apply business rules for classification
    inventory_data['movement_class'] = inventory_data['dio'].apply(get_movement_classification)
    inventory_data['stock_out_risk'] = inventory_data['dio'].apply(get_stock_out_risk_level)

    # ABC Classification
    inventory_data = calculate_abc_classification(inventory_data, settings['use_count_based_abc'])

    # Render filters
    filters_config = get_inventory_filters(inventory_data)
    filter_values = render_filter_section(filters_config)

    # Apply filters
    filtered_data = apply_inventory_filters(inventory_data, filter_values, settings)

    if filtered_data.empty:
        st.info("No data matches the selected filters")
        return

    # === EXPORT BUTTON ===
    export_data = prepare_export_data(
        filtered_data,
        settings['export_section'],
        currency,
        scrap_threshold,
        settings['scrap_days_threshold']
    )

    if not export_data.empty:
        excel_file = create_excel_export(export_data, settings['export_section'], currency)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"Inventory_{settings['export_section'].replace(' ', '_')}_{timestamp}.xlsx"

        st.sidebar.download_button(
            label="üì• Download Excel",
            data=excel_file,
            file_name=filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
            key="download_excel"
        )
        st.sidebar.caption(f"üìä {len(export_data):,} rows ready to export")
    else:
        st.sidebar.info("No data available for selected export option")

    # Calculate and display metrics
    metrics = calculate_inventory_metrics(filtered_data, currency)
    render_kpi_row(metrics)

    st.divider()

    # === STOCK-OUT RISK ALERTS (HIGH PRIORITY) ===
    render_stockout_risk_analysis(filtered_data, currency)

    st.divider()

    # === SLOW-MOVING / OBSOLESCENCE ANALYSIS (PRIMARY FOCUS) ===
    render_scrap_opportunity_analysis(filtered_data, currency, scrap_threshold)

    st.divider()

    # === ABC ANALYSIS ===
    st.subheader("üìä ABC Analysis & Inventory Health")

    col1, col2, col3 = st.columns(3)

    with col1:
        abc_chart = render_abc_analysis_chart(filtered_data, currency)
        if abc_chart:
            render_chart(abc_chart, height=350)

    with col2:
        dio_chart = render_dio_distribution_chart(filtered_data, currency, settings['dio_buckets'])
        if dio_chart:
            render_chart(dio_chart, height=350)

    with col3:
        movement_chart = render_movement_classification_chart(filtered_data, currency)
        if movement_chart:
            render_chart(movement_chart, height=350)

    st.divider()

    # === CATEGORY BENCHMARKING ===
    st.subheader("üèÜ Category Benchmarking")
    category_heatmap = render_category_heatmap(filtered_data, currency)
    if category_heatmap:
        render_chart(category_heatmap, height=250)
    else:
        render_info_box("Unable to generate category heatmap", type="info")

    st.divider()

    # === TOP SLOW MOVERS TABLE ===
    st.subheader("üêå Top 50 Slow-Moving Items by Value")

    value_col = f'stock_value_{currency.lower()}'
    slow_movers = filtered_data[
        filtered_data['movement_class'].isin(['Slow Moving', 'Very Slow Moving', 'Obsolete Risk', 'Dead Stock'])
    ].copy()

    if not slow_movers.empty:
        slow_movers = slow_movers.sort_values(value_col, ascending=False).head(50)

        display_cols = ['sku', 'category', 'abc_class', 'on_hand_qty', 'dio', 'daily_demand',
                       'last_purchase_price', value_col, 'movement_class', 'stock_out_risk']
        available_cols = [col for col in display_cols if col in slow_movers.columns]

        result = slow_movers[available_cols].copy()

        # Format numeric columns
        result['dio'] = result['dio'].round(0).astype(int)
        result['daily_demand'] = result['daily_demand'].round(2)
        result['last_purchase_price'] = result['last_purchase_price'].round(2)
        result[value_col] = result[value_col].round(2)

        # Rename columns for display
        col_names = {
            'sku': 'SKU',
            'category': 'Category',
            'abc_class': 'ABC Class',
            'on_hand_qty': 'On Hand Qty',
            'dio': 'DIO (days)',
            'daily_demand': 'Daily Demand',
            'last_purchase_price': 'Unit Price',
            value_col: f'Stock Value ({currency})',
            'movement_class': 'Movement Class',
            'stock_out_risk': 'Risk Level'
        }
        result = result.rename(columns=col_names)

        render_data_table(
            result,
            max_rows=50
        )
    else:
        render_info_box("No slow-moving items found in current selection", type="success")

    st.divider()

    # === DETAILED INVENTORY RECORDS ===
    with st.expander("üìã View All Inventory Records", expanded=False):
        display_columns = ['sku', 'category', 'abc_class', 'on_hand_qty', 'in_transit_qty',
                          'daily_demand', 'dio', 'movement_class', 'stock_out_risk',
                          'last_purchase_price', value_col]
        available_cols = [col for col in display_columns if col in filtered_data.columns]

        detail_data = filtered_data[available_cols].copy()

        # Format numeric columns
        detail_data['dio'] = detail_data['dio'].round(0).astype(int)
        detail_data['daily_demand'] = detail_data['daily_demand'].round(2)
        detail_data['last_purchase_price'] = detail_data['last_purchase_price'].round(2)
        detail_data[value_col] = detail_data[value_col].round(2)

        # Rename columns
        col_names = {
            'sku': 'SKU',
            'category': 'Category',
            'abc_class': 'ABC Class',
            'on_hand_qty': 'On Hand',
            'in_transit_qty': 'In Transit',
            'daily_demand': 'Daily Demand',
            'dio': 'DIO',
            'movement_class': 'Movement',
            'stock_out_risk': 'Risk',
            'last_purchase_price': 'Unit Price',
            value_col: f'Value ({currency})'
        }
        detail_data = detail_data.rename(columns=col_names)

        render_data_table(
            detail_data,
            max_rows=100
        )

    # === FUTURE: MONTHLY SNAPSHOT STRUCTURE ===
    # Placeholder for future monthly inventory snapshots
    # This section will display historical trends when snapshot data becomes available
    st.divider()
    st.caption("üìÖ Historical Snapshot Tracking - Coming Soon")
    st.caption("Future enhancement: Track inventory levels, DIO trends, and value changes over time")
